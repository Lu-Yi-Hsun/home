{
    "docs": [
        {
            "location": "/",
            "text": "Home\n\u00b6\n\n\n\u9019\u88e1\u662f\u6211\u7684\u5b78\u7fd2\u7b46\u8a18\n\u5167\u5bb9\uff1a\n\n\n\n\n\n\n\u6797\u8ed2\u7530\u6559\u6388 \u7dda\u4e0a\u8ab2\u7a0b\n\n\n\n\n\n\n\u83ab\u51e1python\n\n\n\n\n\n\n\u8ad6\u6587\n\n\n\n\n\n\nAuthor's notes\n\u00b6\n\n\nHi, I'm Anson (\n@lu-yi-hsun\n)\n\u00b6\n\n\nI'm from Taiwan , I love AI\n\n\nversion 2.0",
            "title": "Home"
        },
        {
            "location": "/#home",
            "text": "\u9019\u88e1\u662f\u6211\u7684\u5b78\u7fd2\u7b46\u8a18\n\u5167\u5bb9\uff1a    \u6797\u8ed2\u7530\u6559\u6388 \u7dda\u4e0a\u8ab2\u7a0b    \u83ab\u51e1python    \u8ad6\u6587",
            "title": "Home"
        },
        {
            "location": "/#authors-notes",
            "text": "",
            "title": "Author's notes"
        },
        {
            "location": "/#hi-im-anson-lu-yi-hsun",
            "text": "I'm from Taiwan , I love AI  version 2.0",
            "title": "Hi, I'm Anson (@lu-yi-hsun)"
        },
        {
            "location": "/Crypto currency/investment/",
            "text": "investment\n\u00b6\n\n\nBTC\n\u00b6\n\n\nEOS\n\u00b6\n\n\nIOTA\n\u00b6",
            "title": "investment"
        },
        {
            "location": "/Crypto currency/investment/#investment",
            "text": "",
            "title": "investment"
        },
        {
            "location": "/Crypto currency/investment/#btc",
            "text": "",
            "title": "BTC"
        },
        {
            "location": "/Crypto currency/investment/#eos",
            "text": "",
            "title": "EOS"
        },
        {
            "location": "/Crypto currency/investment/#iota",
            "text": "",
            "title": "IOTA"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/",
            "text": "Bitcoin paper\n\u00b6\n\n\n\n\nBitcoin: A Peer-to-Peer Electronic Cash System \n\n\non chain transaction:\n\n     \u4f7f\u7528\u8005\u767c\u8d77\u4ea4\u6613: \u4ea4\u6613\u9700\u6c42\u8a0a\u606f + \u81ea\u5df1\u7684\u79c1\u9470 \u505a\u6210\u6578\u4f4d\u7c3d\u7ae0\n                 \u2193\n     \u5c07\u4ea4\u6613\u9700\u6c42\u8a0a\u606f\u5ee3\u64ad\u5230Bitcoin\u7db2\u8def\u4e2d\n                 \u2193\n     Bitcoin\u7db2\u8def\u4e2d\u5404\u7bc0\u9ede\u6536\u5230\u6b64\u4ea4\u6613\u8a0a\u606f: \u4ea4\u6613\u9700\u6c42\u8a0a\u606f + \u767c\u8d77\u8005\u516c\u9470 \u505a\u4ea4\u6613\u9a57\u8b49\n                 \u2193\n     \u82e5\u4ea4\u6613\u9a57\u8b49OK\uff0c\u5c31\u5c07\u6b64\u7b46\u4ea4\u6613\u6536\u8d77\u4f86\n                 \u2193\n     \u4ea4\u6613\u6578\u91cf\u8db3\u5920\u6210\u584a\u5f8c\uff0c\u5404\u7bc0\u9ede\u958b\u59cb\u7af6\u722d\n                 \u2193\n     \u7372\u52dd\u7bc0\u9ede\u5c07\u584a\u6253\u5305\u5165\u934a\uff0c\u4e26\u4e14\u5f97\u5230\u6316\u7926\u7684\u734e\u52f5\n\n\n\nhttps://bitcoin.org/bitcoin.pdf\n\n\n1.Introduction\n\u00b6\n\n\n2.Transactions\n\u00b6\n\n\n3.Timestamp Server\n\u00b6\n\n\n4. Proof-of-Work\n\u00b6\n\n\n5. Network\n\u00b6\n\n\n6. Incentive\n\u00b6\n\n\n7. Reclaiming Disk Space\n\u00b6\n\n\n8. Simplified Payment Verification\n\u00b6\n\n\n9. Combining and Splitting Value\n\u00b6\n\n\n10. Privacy\n\u00b6\n\n\n11. Calculations\n\u00b6\n\n\n12. Conclusion\n\u00b6",
            "title": "Bitcoin paper"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#bitcoin-paper",
            "text": "Bitcoin: A Peer-to-Peer Electronic Cash System   on chain transaction:      \u4f7f\u7528\u8005\u767c\u8d77\u4ea4\u6613: \u4ea4\u6613\u9700\u6c42\u8a0a\u606f + \u81ea\u5df1\u7684\u79c1\u9470 \u505a\u6210\u6578\u4f4d\u7c3d\u7ae0\n                 \u2193\n     \u5c07\u4ea4\u6613\u9700\u6c42\u8a0a\u606f\u5ee3\u64ad\u5230Bitcoin\u7db2\u8def\u4e2d\n                 \u2193\n     Bitcoin\u7db2\u8def\u4e2d\u5404\u7bc0\u9ede\u6536\u5230\u6b64\u4ea4\u6613\u8a0a\u606f: \u4ea4\u6613\u9700\u6c42\u8a0a\u606f + \u767c\u8d77\u8005\u516c\u9470 \u505a\u4ea4\u6613\u9a57\u8b49\n                 \u2193\n     \u82e5\u4ea4\u6613\u9a57\u8b49OK\uff0c\u5c31\u5c07\u6b64\u7b46\u4ea4\u6613\u6536\u8d77\u4f86\n                 \u2193\n     \u4ea4\u6613\u6578\u91cf\u8db3\u5920\u6210\u584a\u5f8c\uff0c\u5404\u7bc0\u9ede\u958b\u59cb\u7af6\u722d\n                 \u2193\n     \u7372\u52dd\u7bc0\u9ede\u5c07\u584a\u6253\u5305\u5165\u934a\uff0c\u4e26\u4e14\u5f97\u5230\u6316\u7926\u7684\u734e\u52f5  https://bitcoin.org/bitcoin.pdf",
            "title": "Bitcoin paper"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#1introduction",
            "text": "",
            "title": "1.Introduction"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#2transactions",
            "text": "",
            "title": "2.Transactions"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#3timestamp-server",
            "text": "",
            "title": "3.Timestamp Server"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#4-proof-of-work",
            "text": "",
            "title": "4. Proof-of-Work"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#5-network",
            "text": "",
            "title": "5. Network"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#6-incentive",
            "text": "",
            "title": "6. Incentive"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#7-reclaiming-disk-space",
            "text": "",
            "title": "7. Reclaiming Disk Space"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#8-simplified-payment-verification",
            "text": "",
            "title": "8. Simplified Payment Verification"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#9-combining-and-splitting-value",
            "text": "",
            "title": "9. Combining and Splitting Value"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#10-privacy",
            "text": "",
            "title": "10. Privacy"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#11-calculations",
            "text": "",
            "title": "11. Calculations"
        },
        {
            "location": "/Crypto currency/Bitcoin/Bitcoin paper/#12-conclusion",
            "text": "",
            "title": "12. Conclusion"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/",
            "text": "Block Chain\n\u00b6\n\n\nblock chain on bitcoin\n\n\n\n\n\u65e2\u7136\u9078\u66f4\u9577\u7684\u5206\u652f\uff0c\u90a3\u6211\u7528\u5f88\u4f4e\u7684\u96e3\u5ea6\u53bb\u6c42\u89e3\u600e\u9ebc\u8fa6?\n\n\n\u5ba2\u6236\u7aef\u5728\u773e\u591a\u5206\u652f\u4e2d\u627e\u5230\u7b26\u5408\u7576\u524d\u96e3\u5ea6\u4e14\u6700\u9577\u7684\u3002\n\n\n\n\nView last Block\n\n\n\u6b04\u4f4d\u4ecb\u7d39\n\u00b6\n\n\nsample raw data web\n\n\nsample raw data json\n\n\n{\n\n\n\"hash\"\n:\n\"000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26\"\n,\n\n\n\"size\"\n:\n986803\n,\n\n\n\"height\"\n:\n494333\n,\n\n\n\"version\"\n:\n536870912\n,\n\n\n\"merkleroot\"\n:\n\"eb60eac626c77e2719621f3d2bc5379f43f5a62b5994e184520eb290bb31960c\"\n,\n\n\n\"tx\"\n:[\n\"...........\"\n],\n\n\n\"time\"\n:\n1510663787\n,\n\n\n\"nonce\"\n:\n3267589382\n,\n\n\n\"bits\"\n:\n\"1800ce4b\"\n,\n\n\n\"difficulty\"\n:\n1364422081125.1475\n,\n\n\n\"chainwork\"\n:\n\"000000000000000000000000000000000000000000b09e2108dc9f58fa17f83e\"\n,\n\n\n\"confirmations\"\n:\n9\n,\n\n\n\"previousblockhash\"\n:\n\"0000000000000000001072fdaa28f5b128009e8580f6080ca82063f9a912cbbc\"\n,\n\"nextblockhash\"\n:\n\"0000000000000000000960da72f18edad9d101fb5c3a2ac1ecbfea7600d82575\"\n,\n\n\n\"reward\"\n:\n12.5\n,\n\n\n\"isMainChain\"\n:\ntrue\n,\n\n\n\"poolInfo\"\n:{\n\"poolName\"\n:\n\"AntMiner\"\n,\n\"url\"\n:\n\"https://bitmaintech.com/\"\n}}\n\n\n\n\n\n\n\nhash\n\u00b6\n\n\n\n\nBlock hashing algorithm\n\n\nhash256(hash256(Version+hashPrevBlock+hashMerkleRoot+Time+Bits+Nonce))\n\n\n\n\n\n\n\n\n\n\nField\n\n\nPurpose\n\n\nUpdated when...\n\n\nSize (Bytes)\n\n\n\n\n\n\n\n\n\n\nVersion\n\n\nBlock version number\n\n\nYou upgrade the software and it specifies a new version\n\n\n4\n\n\n\n\n\n\nhashPrevBlock\n\n\n256-bit hash of the previous block header\n\n\nA new block comes in\n\n\n32\n\n\n\n\n\n\nhashMerkleRoot\n\n\n256-bit hash based on all of the transactions in the block\n\n\nA transaction is accepted\n\n\n32\n\n\n\n\n\n\nTime\n\n\nCurrent timestamp as seconds since 1970-01-01T00:00 UTC\n\n\nEvery few seconds\n\n\n4\n\n\n\n\n\n\nBits\n\n\nCurrent target in compact format\n\n\nThe difficulty is adjusted\n\n\n4\n\n\n\n\n\n\nNonce\n\n\n32-bit number (starts at 0)\n\n\nA hash is tried (increments)\n\n\n4\n\n\n\n\n\n\nhttps://en.bitcoin.it/wiki/Block_hashing_algorithm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nThe output of blockexplorer displays the hash values as big-endian numbers\n\nbut python3 hashlib is little end\n\n\n\n\nCODE on Python3\n'''\n\n\nsource\n\n\nsupport blockexplorer & blockchain\n\n\nhttps://blockexplorer.com/api/block/000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26\n\n\nor\n\n\nhttps://blockchain.info/rawblock/000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26\n\n\n'''\n\n\nimport\n \nhashlib\n\n\nimport\n \ncodecs\n\n\nimport\n \nstruct\n\n\n\n'''\n\n\nimport hashlib using \"little-end\" but blockexplorer is \"biggest-end\" ,we need convert biggest-end to little-end\n\n\n'''\n\n\ndef\n \nbtol\n(\nst\n):\n\n    \nif\n \nlen\n(\nst\n)\n%\n2\n \n!=\n0\n:\n\n        \nreturn\n \n\"error need 2 pair\"\n\n    \nelse\n:\n\n        \nans\n=\n\"\"\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nint\n(\nlen\n(\nst\n)\n/\n2\n)):\n\n            \nindex\n=\ni\n*\n2\n\n            \nans\n=\nst\n[\nindex\n]\n+\nst\n[\nindex\n+\n1\n]\n+\nans\n\n        \nreturn\n \nans\n\n\n''' we can get sample on blockexplorer '''\n    \n\nVersion\n=\n\"536870912\"\n \n#4bytes so need 8 hex\n\n\nhashPrevBlock\n=\n\"0000000000000000001072fdaa28f5b128009e8580f6080ca82063f9a912cbbc\"\n#32bytes\n\n\nhashMerkleRoot\n=\n\"eb60eac626c77e2719621f3d2bc5379f43f5a62b5994e184520eb290bb31960c\"\n#32bytes\n\n\nTime\n=\n\"1510663787\"\n#4bytes\n\n\nBits\n=\n\"1800ce4b\"\n#4bytes\n\n\nNonce\n=\n\"3267589382\"\n#4bytes\n\n\n\ncontrol\n=\ninput\n(\n\"blockexplorer.com Data input \n\\\"\n1\n\\\"\n blockchain.info Date input \n\\\"\n2\n\\\"\n \n\\n\n\"\n)\n\n\n\nif\n \ncontrol\n.\nisdecimal\n():\n\n    \nif\n \nint\n(\ncontrol\n)\n==\n1\n:\n\n        \npass\n\n    \nelif\n \nint\n(\ncontrol\n)\n==\n2\n:\n\n        \nBits\n=\nstr\n(\nhex\n(\nint\n(\nBits\n))[\n2\n:])\n.\nzfill\n(\n8\n)\n\n    \nelse\n:\n\n        \nprint\n(\n\"error please input 1 or 2\"\n)\n\n        \nexit\n(\n1\n)\n\n\nelse\n:\n\n    \nprint\n(\n\"error please input 1 or 2\"\n)\n\n    \nexit\n(\n1\n)\n\n\n\nheader_hex\n \n=\n \n(\n\n\nbtol\n(\nstr\n(\nhex\n(\nint\n(\nVersion\n))[\n2\n:])\n.\nzfill\n(\n8\n))\n \n+\n\n\nbtol\n(\nhashPrevBlock\n)\n \n+\n\n\nbtol\n(\nhashMerkleRoot\n)\n \n+\n\n\nbtol\n(\nstr\n(\nhex\n(\nint\n(\nTime\n))[\n2\n:])\n.\nzfill\n(\n8\n))\n \n+\n\n\nbtol\n(\nBits\n)\n \n+\n\n\nbtol\n(\nstr\n(\nhex\n(\nint\n(\nNonce\n))[\n2\n:]))\n.\nzfill\n(\n8\n))\n\n\n\n\n\nheader_bin\n \n=\n \ncodecs\n.\ndecode\n(\nheader_hex\n,\n \n\"hex\"\n)\n\n\nhash\n \n=\n \nhashlib\n.\nsha256\n(\nhashlib\n.\nsha256\n(\nheader_bin\n)\n.\ndigest\n())\n.\ndigest\n()\n\n\n\n\n'''we want to view biggest-end'''\n\n\nprint\n(\n\"view hash by big-endian\"\n)\n\n\nprint\n \n(\ncodecs\n.\nencode\n(\nhash\n[::\n-\n1\n],\n \n\"hex\"\n))\n\n\n\n\n\n\nsize\n\u00b6\n\n\nSize (bytes)\n\n\n\n\nheight\n\u00b6\n\n\n\u4ee3\u8868\u524d\u9762\u6709\u591a\u5c11\u584ablock chain ,\u5275\u4e16\u7b2c\u4e00\u500bblockchain\u7684hight\u503c\u70ba\u96f6\n\n\n\n\nversion\n\u00b6\n\n\nBlock version number    You upgrade the software and it specifies a new version 4bytes\n\n\n\n\nmerkleroot\n\u00b6\n\n\n\n\nH_{A} = SHA_{256}(SHA_{256}(Tx A))\nH_{A} = SHA_{256}(SHA_{256}(Tx A))\n\n\nH_{AB} = SHA_{256}(SHA_{256}(H_{A}+H_{B}))\nH_{AB} = SHA_{256}(SHA_{256}(H_{A}+H_{B}))\n\n\ntx(Transactions)\n\u00b6\n\n\n\u4ea4\u6613\u8a0a\u606f\n\n\n\n\n\ntime\n\u00b6\n\n\nCurrent timestamp as seconds since 1970-01-01T00:00 UTC\n\n\n\n\nnonce\n\u00b6\n\n\n\n\nWarning\n\n\nnonce\u53ea\u67094bytes\u4e26\u4e0d\u4ee3\u8868\u53ea\u9700\u8981\n2^{32}\n2^{32}\n\u5c31\u53ef\u4ee5\u7834\u89e3sha256\n\n\u6709\u53ef\u80fd\u7b97\u5b8c\u9084\u627e\u4e0d\u5230\u7b54\u6848,\u5c31\u5fc5\u9808\u66f4\u6539\u5176\u4ed6\u6b04\u4f4d\u597d\u8b93hash\u7b26\u5408\u898f\u5b9a\n\n\n\n\n\n\nbits\n\u00b6\n\n\nbits to target\n\n\nsolution1\n\u00b6\n\n\n\n\nbits mean\n\n\nlike 0x1d00ffff\n\nall large is 32 bytes\n\n* 0x\n\\color{blue}{1d}\n\\color{blue}{1d}\n --- \n(1d)_{16}=(26)_{10}\n(1d)_{16}=(26)_{10}\n so we know 26 bytes after 00ffff \n\n* 0x\n\\color{red}{00ffff}\n\\color{red}{00ffff}\n --- target prefix\n\n\n000000\\color{red}{00ffff}\\color{blue}{0000000000000000000000000000000000000000000000000000}\n000000\\color{red}{00ffff}\\color{blue}{0000000000000000000000000000000000000000000000000000}\n\n\n\n\nsolution2\n\u00b6\n\n\nbetter performence\n\nexponent=bits[0~1]\n\ncoefficient=bits[2~7]\n\ntarget = coefficient * 2^(8 * (exponent \u2013 3))\n\n\n\n\n\nCODE on Python3\n\n\nbite to target\n\nsolution1\n\nbits=\"1d00ffff\"\nprint(bits[2:].ljust(2*int(bits[0:2],16),'0').zfill(64))\n\n\nsolution2\n\nprint(hex(0x00ffff*2**(8*(0x1d - 3)))[2:].zfill(64))\n\n\n\n\n\n\n\ndifficulty\n\u00b6\n\n\n\n\n\u516c\u5f0f\n\n\n\u5169\u7a2edifficulty \u4e00\u822c\u4f7f\u7528bdiff\n\n\nbdiff \u5b9a\u7fa9:1\u56f0\u96e3\u5ea6\uff08difficulty\uff09\u7684bits=0x1D00FFFF\n  \n\n\npdiff-target:0x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\n\n\n1=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(0x1D00FFFF)}\n1=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(0x1D00FFFF)}\n\nexponent=bits[0-1]\n\ncoefficient=bits[2-7]\n\n\nf_{conv}(bits)\nf_{conv}(bits)\n=coefficient * 2^(8 * (exponent \u2013 3))\n\n\nf_{conv}(\\color{red}{1D}\\color{blue}{00FFFF})=\\color{blue}{00FFFF}_{16} * 2^{( 8 *( \\color{red}{1D}_{16}  -  3 ))}\nf_{conv}(\\color{red}{1D}\\color{blue}{00FFFF})=\\color{blue}{00FFFF}_{16} * 2^{( 8 *( \\color{red}{1D}_{16}  -  3 ))}\n \n\n\ndifficulty=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(bits) }\ndifficulty=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(bits) }\n\n\n\n\n\n\ntarget mean\n\n\ntarget=f_{conv}(bits)\ntarget=f_{conv}(bits)\n\ntarget\u610f\u601d\u5c31\u662f\u5728\u6316\u7926\u7684\u6642\u5019nonce\u8a72\u600e\u9ebc\u8abf\u6574\u597d\u8b93hash\n\ntarget \u8d8a\u5c0f\u4ee3\u8868\u96e3\u5ea6\u8d8a\u5927\n\n\n\n\n\n\nwe know bits=1800ce4b difficulty(bdiff)=?\n\n\ndifficulty\n=\n0x00ffff\n*\n2\n**\n(\n8\n*\n(\n0x1d\n \n-\n \n3\n))\n/\nfloat\n(\n0x00ce4b\n*\n2\n**\n(\n8\n*\n(\n0x18\n \n-\n \n3\n)))\n\n\n\nAnswer:difficulty=1364422081125.1475 \n\n\n\n\nBitcoin Difficulty\n\n\n\n\nchainwork\n\u00b6\n\n\n\n\n\u7bc4\u4f8b\n\n\nset chainwork=10Hash\n\u4f60\u7684\u96fb\u81661H/s \n\u4ee3\u8868\u4f60\u8981\u7b97\u73a9\u9019\u4e32\u5340\u584a\u7df4\u5340\u898110\u79d2\n\n\n\n\n\n\nconfirmations\n\u00b6\n\n\nConfirmation\n\n\u4ee3\u8868\u8a72blockchain\u7684\u7248\u672c\u4e4b\u4e0b \u524d\u9762\u6709\u591a\u5c11\u584ablock\n\u4e00\u822c\u4f86\u8aaa\u7b49\u5f856\u584a\u5c31\u53ef\u4ee5\u78ba\u8a8d\u4ea4\u6613\n\n\n\n\npreviousblockhash\n\u00b6\n\n\n\u524d\u4e00\u500b\u5340\u584a\u93c8\u7684HASH\n\n\n\n\nreward\n\u00b6\n\n\n\u7b97\u51fa\u8a72\u5340\u584a\u7df4\u6240\u7d66\u7684\u734e\u52f5 \n\n2009~2012 50BTC\n\n2013~2016 25BTC\n\n2017~2020 12.5BTC\n\n2020~     6.25BTC \n\n\n\n\nisMainChain\n\u00b6\n\n\n\u662f\u4e0d\u662f\u6700\u9577\u7684\u90a3\u500b\u5340\u584a\u7df4\n\n\npoolInfo\n\u00b6\n\n\n\u7926\u5834\u8cc7\u8a0a\n\n\n\n\nmining\n\u00b6\n\n\nexample \"bits\":\"1800ce4b\"\n\n\ntarget=(0x00ce4b)_{16} * 2^{(8 * ((0x18)_{16} \u2013 3))}\ntarget=(0x00ce4b)_{16} * 2^{(8 * ((0x18)_{16} \u2013 3))}\n\n\n\n\nNote\n\n\n\u6211\u5011\u60f3\u8981\u85c9\u7531\u66f4\u52d5nonce \u4f86\u8b93hash<target\n\n\n\n\ntarget=\n000000000000000000CE4B000000000000000000000000000000000000000000\n                                                        \n\nhash=  \n000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26\n\n\nHash Rate\n\u00b6\n\n\n\n\n\u8a08\u7b97\u99ed\u5ba2\u8981\u653b\u64ca51%\u7684\u96e3\u5ea6\n\n\n\u786c\u9ad4\u53c3\u8003\u6578\u64da\n\n\nHashrate\n\n\u6ce8\u610f\uff1a\u8a72\u63db\u7b97\u53ea\u80fd\u53c3\u8003\u7528\n\nIntel Xeon E5-2698 V4 \n\\simeq\n\\simeq\n 800H/s\n\nIntel Xeon Phi 7210 \n\\simeq\n\\simeq\n 600H/s\n\n\n\u5929\u548c\u4e8c\u865f\n\n32,000\u9846Xeon E5\u4e3b\u8655\u7406\u5668\u548c48,000\u500bXeon Phi\u5354\u8655\u7406\u5668\n\n\u5929\u548c\u4e8c\u865f:800*32,000+48,000*600=54400000H/s=54400000MH/s=54400GH/s\n\n\u5168\u7403\u6bd4\u7279\u5e63Hashrate\uff1a7602699877 GH/s\n\n\u5168\u7403\u6bd4\u7279\u5e63/\u5929\u548c\u4e8c\u865f=139755\n\n\u7d50\u8ad6\u9700\u898113/2\u842c\u7d44\u5929\u548c\u4e8c\u865f\u8d85\u7d1a\u96fb\u8166\u624d\u80fd\u8d85\u904e51%\u5168\u4e16\u754c\u7684\u96fb\u8166\n\n\u7531\u65bc\u76ee\u524d\u6bd4\u7279\u5e63\u662f\u4f7f\u7528ASIC\u6240\u4ee5\u6548\u80fd\u624d\u6703\u5982\u6b64\u4e4b\u5927\u662fcpu\u6240\u7121\u6cd5\u6279\u64ec\n\n\n\n\n256/8\n32bytes",
            "title": "Block Chain"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#block-chain",
            "text": "block chain on bitcoin   \u65e2\u7136\u9078\u66f4\u9577\u7684\u5206\u652f\uff0c\u90a3\u6211\u7528\u5f88\u4f4e\u7684\u96e3\u5ea6\u53bb\u6c42\u89e3\u600e\u9ebc\u8fa6?  \u5ba2\u6236\u7aef\u5728\u773e\u591a\u5206\u652f\u4e2d\u627e\u5230\u7b26\u5408\u7576\u524d\u96e3\u5ea6\u4e14\u6700\u9577\u7684\u3002   View last Block",
            "title": "Block Chain"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#_1",
            "text": "sample raw data web  sample raw data json  {  \"hash\" : \"000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26\" ,  \"size\" : 986803 ,  \"height\" : 494333 ,  \"version\" : 536870912 ,  \"merkleroot\" : \"eb60eac626c77e2719621f3d2bc5379f43f5a62b5994e184520eb290bb31960c\" ,  \"tx\" :[ \"...........\" ],  \"time\" : 1510663787 ,  \"nonce\" : 3267589382 ,  \"bits\" : \"1800ce4b\" ,  \"difficulty\" : 1364422081125.1475 ,  \"chainwork\" : \"000000000000000000000000000000000000000000b09e2108dc9f58fa17f83e\" ,  \"confirmations\" : 9 ,  \"previousblockhash\" : \"0000000000000000001072fdaa28f5b128009e8580f6080ca82063f9a912cbbc\" , \"nextblockhash\" : \"0000000000000000000960da72f18edad9d101fb5c3a2ac1ecbfea7600d82575\" ,  \"reward\" : 12.5 ,  \"isMainChain\" : true ,  \"poolInfo\" :{ \"poolName\" : \"AntMiner\" , \"url\" : \"https://bitmaintech.com/\" }}",
            "title": "\u6b04\u4f4d\u4ecb\u7d39"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#hash",
            "text": "Block hashing algorithm  hash256(hash256(Version+hashPrevBlock+hashMerkleRoot+Time+Bits+Nonce))      Field  Purpose  Updated when...  Size (Bytes)      Version  Block version number  You upgrade the software and it specifies a new version  4    hashPrevBlock  256-bit hash of the previous block header  A new block comes in  32    hashMerkleRoot  256-bit hash based on all of the transactions in the block  A transaction is accepted  32    Time  Current timestamp as seconds since 1970-01-01T00:00 UTC  Every few seconds  4    Bits  Current target in compact format  The difficulty is adjusted  4    Nonce  32-bit number (starts at 0)  A hash is tried (increments)  4    https://en.bitcoin.it/wiki/Block_hashing_algorithm         Warning  The output of blockexplorer displays the hash values as big-endian numbers \nbut python3 hashlib is little end   CODE on Python3 '''  source  support blockexplorer & blockchain  https://blockexplorer.com/api/block/000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26  or  https://blockchain.info/rawblock/000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26  '''  import   hashlib  import   codecs  import   struct  '''  import hashlib using \"little-end\" but blockexplorer is \"biggest-end\" ,we need convert biggest-end to little-end  '''  def   btol ( st ): \n     if   len ( st ) % 2   != 0 : \n         return   \"error need 2 pair\" \n     else : \n         ans = \"\" \n         for   i   in   range ( int ( len ( st ) / 2 )): \n             index = i * 2 \n             ans = st [ index ] + st [ index + 1 ] + ans \n         return   ans  ''' we can get sample on blockexplorer '''      Version = \"536870912\"   #4bytes so need 8 hex  hashPrevBlock = \"0000000000000000001072fdaa28f5b128009e8580f6080ca82063f9a912cbbc\" #32bytes  hashMerkleRoot = \"eb60eac626c77e2719621f3d2bc5379f43f5a62b5994e184520eb290bb31960c\" #32bytes  Time = \"1510663787\" #4bytes  Bits = \"1800ce4b\" #4bytes  Nonce = \"3267589382\" #4bytes  control = input ( \"blockexplorer.com Data input  \\\" 1 \\\"  blockchain.info Date input  \\\" 2 \\\"   \\n \" )  if   control . isdecimal (): \n     if   int ( control ) == 1 : \n         pass \n     elif   int ( control ) == 2 : \n         Bits = str ( hex ( int ( Bits ))[ 2 :]) . zfill ( 8 ) \n     else : \n         print ( \"error please input 1 or 2\" ) \n         exit ( 1 )  else : \n     print ( \"error please input 1 or 2\" ) \n     exit ( 1 )  header_hex   =   (  btol ( str ( hex ( int ( Version ))[ 2 :]) . zfill ( 8 ))   +  btol ( hashPrevBlock )   +  btol ( hashMerkleRoot )   +  btol ( str ( hex ( int ( Time ))[ 2 :]) . zfill ( 8 ))   +  btol ( Bits )   +  btol ( str ( hex ( int ( Nonce ))[ 2 :])) . zfill ( 8 ))  header_bin   =   codecs . decode ( header_hex ,   \"hex\" )  hash   =   hashlib . sha256 ( hashlib . sha256 ( header_bin ) . digest ()) . digest ()  '''we want to view biggest-end'''  print ( \"view hash by big-endian\" )  print   ( codecs . encode ( hash [:: - 1 ],   \"hex\" ))",
            "title": "hash"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#size",
            "text": "Size (bytes)",
            "title": "size"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#height",
            "text": "\u4ee3\u8868\u524d\u9762\u6709\u591a\u5c11\u584ablock chain ,\u5275\u4e16\u7b2c\u4e00\u500bblockchain\u7684hight\u503c\u70ba\u96f6",
            "title": "height"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#version",
            "text": "Block version number    You upgrade the software and it specifies a new version 4bytes",
            "title": "version"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#merkleroot",
            "text": "H_{A} = SHA_{256}(SHA_{256}(Tx A)) H_{A} = SHA_{256}(SHA_{256}(Tx A))  H_{AB} = SHA_{256}(SHA_{256}(H_{A}+H_{B})) H_{AB} = SHA_{256}(SHA_{256}(H_{A}+H_{B}))",
            "title": "merkleroot"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#txtransactions",
            "text": "\u4ea4\u6613\u8a0a\u606f",
            "title": "tx(Transactions)"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#time",
            "text": "Current timestamp as seconds since 1970-01-01T00:00 UTC",
            "title": "time"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#nonce",
            "text": "Warning  nonce\u53ea\u67094bytes\u4e26\u4e0d\u4ee3\u8868\u53ea\u9700\u8981 2^{32} 2^{32} \u5c31\u53ef\u4ee5\u7834\u89e3sha256 \n\u6709\u53ef\u80fd\u7b97\u5b8c\u9084\u627e\u4e0d\u5230\u7b54\u6848,\u5c31\u5fc5\u9808\u66f4\u6539\u5176\u4ed6\u6b04\u4f4d\u597d\u8b93hash\u7b26\u5408\u898f\u5b9a",
            "title": "nonce"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#bits",
            "text": "bits to target",
            "title": "bits"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#solution1",
            "text": "bits mean  like 0x1d00ffff \nall large is 32 bytes \n* 0x \\color{blue}{1d} \\color{blue}{1d}  ---  (1d)_{16}=(26)_{10} (1d)_{16}=(26)_{10}  so we know 26 bytes after 00ffff  \n* 0x \\color{red}{00ffff} \\color{red}{00ffff}  --- target prefix  000000\\color{red}{00ffff}\\color{blue}{0000000000000000000000000000000000000000000000000000} 000000\\color{red}{00ffff}\\color{blue}{0000000000000000000000000000000000000000000000000000}",
            "title": "solution1"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#solution2",
            "text": "better performence exponent=bits[0~1]\n\ncoefficient=bits[2~7]\n\ntarget = coefficient * 2^(8 * (exponent \u2013 3))   CODE on Python3  bite to target \nsolution1 bits=\"1d00ffff\"\nprint(bits[2:].ljust(2*int(bits[0:2],16),'0').zfill(64)) \nsolution2 print(hex(0x00ffff*2**(8*(0x1d - 3)))[2:].zfill(64))",
            "title": "solution2"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#difficulty",
            "text": "\u516c\u5f0f  \u5169\u7a2edifficulty \u4e00\u822c\u4f7f\u7528bdiff  bdiff \u5b9a\u7fa9:1\u56f0\u96e3\u5ea6\uff08difficulty\uff09\u7684bits=0x1D00FFFF     pdiff-target:0x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF  1=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(0x1D00FFFF)} 1=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(0x1D00FFFF)} \nexponent=bits[0-1] \ncoefficient=bits[2-7]  f_{conv}(bits) f_{conv}(bits) =coefficient * 2^(8 * (exponent \u2013 3))  f_{conv}(\\color{red}{1D}\\color{blue}{00FFFF})=\\color{blue}{00FFFF}_{16} * 2^{( 8 *( \\color{red}{1D}_{16}  -  3 ))} f_{conv}(\\color{red}{1D}\\color{blue}{00FFFF})=\\color{blue}{00FFFF}_{16} * 2^{( 8 *( \\color{red}{1D}_{16}  -  3 ))}    difficulty=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(bits) } difficulty=\\frac{f_{conv}(0x1D00FFFF)}{f_{conv}(bits) }    target mean  target=f_{conv}(bits) target=f_{conv}(bits) \ntarget\u610f\u601d\u5c31\u662f\u5728\u6316\u7926\u7684\u6642\u5019nonce\u8a72\u600e\u9ebc\u8abf\u6574\u597d\u8b93hash \ntarget \u8d8a\u5c0f\u4ee3\u8868\u96e3\u5ea6\u8d8a\u5927    we know bits=1800ce4b difficulty(bdiff)=?  difficulty = 0x00ffff * 2 ** ( 8 * ( 0x1d   -   3 )) / float ( 0x00ce4b * 2 ** ( 8 * ( 0x18   -   3 )))  \nAnswer:difficulty=1364422081125.1475    Bitcoin Difficulty",
            "title": "difficulty"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#chainwork",
            "text": "\u7bc4\u4f8b  set chainwork=10Hash\n\u4f60\u7684\u96fb\u81661H/s \n\u4ee3\u8868\u4f60\u8981\u7b97\u73a9\u9019\u4e32\u5340\u584a\u7df4\u5340\u898110\u79d2",
            "title": "chainwork"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#confirmations",
            "text": "Confirmation \n\u4ee3\u8868\u8a72blockchain\u7684\u7248\u672c\u4e4b\u4e0b \u524d\u9762\u6709\u591a\u5c11\u584ablock\n\u4e00\u822c\u4f86\u8aaa\u7b49\u5f856\u584a\u5c31\u53ef\u4ee5\u78ba\u8a8d\u4ea4\u6613",
            "title": "confirmations"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#previousblockhash",
            "text": "\u524d\u4e00\u500b\u5340\u584a\u93c8\u7684HASH",
            "title": "previousblockhash"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#reward",
            "text": "\u7b97\u51fa\u8a72\u5340\u584a\u7df4\u6240\u7d66\u7684\u734e\u52f5  \n2009~2012 50BTC \n2013~2016 25BTC \n2017~2020 12.5BTC \n2020~     6.25BTC",
            "title": "reward"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#ismainchain",
            "text": "\u662f\u4e0d\u662f\u6700\u9577\u7684\u90a3\u500b\u5340\u584a\u7df4",
            "title": "isMainChain"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#poolinfo",
            "text": "\u7926\u5834\u8cc7\u8a0a",
            "title": "poolInfo"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#mining",
            "text": "example \"bits\":\"1800ce4b\"  target=(0x00ce4b)_{16} * 2^{(8 * ((0x18)_{16} \u2013 3))} target=(0x00ce4b)_{16} * 2^{(8 * ((0x18)_{16} \u2013 3))}   Note  \u6211\u5011\u60f3\u8981\u85c9\u7531\u66f4\u52d5nonce \u4f86\u8b93hash<target   target= 000000000000000000CE4B000000000000000000000000000000000000000000                                                          \nhash=   000000000000000000011f35a721c6065b447eef96640ce0ca9ba9a98edd9a26",
            "title": "mining"
        },
        {
            "location": "/Crypto currency/Bitcoin/Block Chain/#hash-rate",
            "text": "\u8a08\u7b97\u99ed\u5ba2\u8981\u653b\u64ca51%\u7684\u96e3\u5ea6  \u786c\u9ad4\u53c3\u8003\u6578\u64da  Hashrate \n\u6ce8\u610f\uff1a\u8a72\u63db\u7b97\u53ea\u80fd\u53c3\u8003\u7528 \nIntel Xeon E5-2698 V4  \\simeq \\simeq  800H/s \nIntel Xeon Phi 7210  \\simeq \\simeq  600H/s  \u5929\u548c\u4e8c\u865f \n32,000\u9846Xeon E5\u4e3b\u8655\u7406\u5668\u548c48,000\u500bXeon Phi\u5354\u8655\u7406\u5668 \n\u5929\u548c\u4e8c\u865f:800*32,000+48,000*600=54400000H/s=54400000MH/s=54400GH/s \n\u5168\u7403\u6bd4\u7279\u5e63Hashrate\uff1a7602699877 GH/s \n\u5168\u7403\u6bd4\u7279\u5e63/\u5929\u548c\u4e8c\u865f=139755 \n\u7d50\u8ad6\u9700\u898113/2\u842c\u7d44\u5929\u548c\u4e8c\u865f\u8d85\u7d1a\u96fb\u8166\u624d\u80fd\u8d85\u904e51%\u5168\u4e16\u754c\u7684\u96fb\u8166 \n\u7531\u65bc\u76ee\u524d\u6bd4\u7279\u5e63\u662f\u4f7f\u7528ASIC\u6240\u4ee5\u6548\u80fd\u624d\u6703\u5982\u6b64\u4e4b\u5927\u662fcpu\u6240\u7121\u6cd5\u6279\u64ec   256/8\n32bytes",
            "title": "Hash Rate"
        },
        {
            "location": "/Machine Learning/Introduction/",
            "text": "Introduction\n\u00b6\n\n\n\n\n\u4ec0\u9ebc\u6642\u5019\u53ef\u4ee5\u4f7f\u7528\u6a5f\u5668\u5b78\u7fd2\uff1f\n 1.\u8981\u6709\u898f\u5247 2.\u4e0d\u5bb9\u6613\u5beb\u51fa\u4f86\u7684\u898f\u5247(\u8fa8\u8b58\u5716\u7247)3.\u6709\u8db3\u5920\u7684\u8cc7\u6599\n  \u6a5f\u5668\u5b78\u7fd2\u4f5c\u6cd5\uff1f\n  \u5f9e\u8cc7\u6599\u51fa\u767c\u53bb\u5b78\u7fd2\n\n\n\n\nLearning Model\n\u00b6\n\n\n\u76ee\u6a19\uff1a\u5f9eA\u88e1\u9762\u5f88\u591a\u500bH\u4e2d\u9078\u4e00\u500b\u4f86\u4ee3\u8868g,\u5e0c\u671bg\u8d8a\u63a5\u8fd1f\n\u53e6\u4e00\u7a2e\u89e3\u91cb\u65b9\u6cd5\uff1a\u5728\u65b9\u7a0b\u5f0f\u88e1\u9762,\u6709H\u500b\u89e3,g\u5c31\u662f\u9078\u5230\u6700\u597d\u7684\u89e3 \n\n\n\n\nD:\u8ddff\u6709\u95dc\u7684\u8cc7\u6599 \n\n\nA:\u6a5f\u5668\u5b78\u7fd2\u7684\u6f14\u7b97\u6cd5 \n\n\nH:A\u6f14\u7b97\u6cd5\u88e1\u9762\u6709\u5f88\u591a\u500b\u5047\u8aaaH\n\n\ng:\u63a5\u8fd1\u771f\u5be6f\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578) \n\n\nf:\u5922\u60f3\u5f97\u5230\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578)\n\n\n\n\n\n\nExample\n\n\nD:your data input to x\n\nA: machine learning algorithm is y=ax \n\nH:H\u2208\n\\mathbb{Q}\n\\mathbb{Q}\n all possible in this algorithm {y=0.3x,y=6x,y=6.7x...}\n\ng: our machine learning get answer y=2.9999x it close to f\n\nf:we want to get this function y=3x\n\n\n\n\n\n\n\n\nTypes of Machine Learning\n\u00b6\n\n\nOutput Space\n\u00b6\n\n\n(\u8981\u554f\u4ec0\u9ebc\u554f\u984c)\n\n\n\n\n\n\n\n\nBinary Classification\n\n\nMulticlass classification\n\n\nRegression\n\n\nStructured Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Label\n\u00b6\n\n\n(\u62ff\u5230\u4e0d\u540c\u6a19\u8a18\u7684\u8cc7\u6599,\u8981\u600e\u8655\u7406)\n\n\n\n\n\n\n\n\nSupervised\n\n\nSemi-supervised\n\n\n\n\n\n\n\n\n\n\nSample:Classification \n  \n \u5df2\u7d93\u6a19\u8a18\u597d\u8cc7\u6599\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnsupervised\n\n\nReinforcement Learning (\u589e\u5f37\u5f0f\u5b78\u7fd2)\n\n\n\n\n\n\n\n\n\n\nSample: Clustering \nclustering(\u5206\u7fa4)density estimation:\u54ea\u4e9b\u5730\u65b9\u6bd4\u8f03\u7a20\u5bc6\u61c9\u7528ex.\u54ea\u88e1\u6bd4\u8f03\u5e38\u767c\u751f\u4e8b\u6545outlier detection:\u627e\u51fa\u7570\u5e38\u7684\u8cc7\u6599,\u56e0\u70ba\u7570\u5e38\u8cc7\u6599\u5f88\u5c11\n\n\n\u8ddf\u8a13\u7df4\u5bf5\u7269\u4e00\u6a23,\u5c0d\u7d66\u734e\u52f5,\u932f\u7d66\u61f2\u7f70\n\n\n\n\n\n\n\n\n\n\nProtocol\n\u00b6\n\n\n\u8f38\u5165\u8cc7\u6599\u7684\u65b9\u6cd5\nf \\implies (x_{n},y_{n})\nf \\implies (x_{n},y_{n})\n\n\n\n\n\n\n\n\nbatch\n\n\nOnline\n\n\nactive\n\n\n\n\n\n\n\n\n\n\n\u6210\u6279\u7684\u8cc7\u6599\u4f86\u5b78\u7fd2\n\n\n\u4e00\u7b46\u4e00\u7b46\u8cc7\u6599\u4f86\u5b78\u7fd2,\u9047\u5230\u932f\u8aa4\u5728\u6539\u6b63ex.PLA,Reinforcement Learning\n\n\n\u6a5f\u5668\u81ea\u5df1\u554f\u554f\u984c,\u7576\u8cc7\u6599\u5f88\u5c11\u6216\u5f88\u8cb4\u53ef\u4ee5\u4f7f\u7528,\u4e5f\u5e0c\u671b\u6a5f\u5668\u5b78\u7fd2\u901f\u5ea6\u52a0\u5feb\u8ddf\u4eba\u4e00\u6a23ex.\u6a5f\u5668\u81ea\u5df1\u5beb\u4e00\u500b\u6578\u5b57,\u53cd\u904e\u4f86\u554f\u4eba\u4f86\u5b78\u7fd2\n\n\n\n\n\n\n\n\n\n\nInput Space\n\u00b6\n\n\n\u8cc7\u6599\u7a2e\u985e\n\\mathcal{X}\n\\mathcal{X}\n\n\u8d8a\u62bd\u8c61\u7684\u8cc7\u6599\u96fb\u8166\u8d8a\u96e3\u5b78\u7fd2\n\n\n\n\nSample\n\n\nMnist\u4f7f\u7528Multilayer perceptron \u662f\u4f7f\u7528raw pixel\u8cc7\u6599 \u6e96\u78ba\u5ea691%\n\nMnist\u4f7f\u7528CNN\u6e96\u78ba\u5ea6\u5927\u7d0498~99%\n\n\u7531\u6b64\u53ef\u77e5\u7576Raw\u7684\u8cc7\u6599\u8b8a\u6210Concrete\u96fb\u8166\u5c31\u80fd\u5b78\u5f97\u8d8a\u4f86\u8d8a\u597d\n\n\n\n\n\n\n\n\n\n\nConcrete(\u5305\u542b\u4eba\u985e\u667a\u6167)\n\n\nRaw\n\n\nabstract(\u6700\u62bd\u8c61)\n\n\n\n\n\n\n\n\n\n\n\u8cc7\u6599\u88e1\u9762\u6709\u4eba\u985e\u7684\u667a\u6167,\u6709\u9810\u5148\u8655\u7406\u7684\u8cc7\u6599,\u7bc4\u4f8b:\u8fa8\u8b581\u8ddf5 \u7528\u4eba\u8166\u5beb\u4e0b\u898f\u5247\u5230\u5e95\u9019\u5f35\u5716\u6709\u6c92\u6709\u5c0d\u7a31\u6216\u662f\u5bc6\u5ea6\u5982\u4f55\n\n\n\u539f\u59cb\u7684\u8cc7\u6599,\u97f3\u8a0a,bit,pixel,\u7bc4\u4f8b:\u76f4\u63a5\u8f38\u5165pixel,\u4f46pixel\u6c92\u6709\u4eba\u985e\u667a\u6167\u53ea\u662f\u55ae\u7d14\u7684\u6578\u64da\n\n\n\u62bd\u8c61\u7684\u8cc7\u6599ex.\u4f7f\u7528\u8005id\u7de8\u865f\n\n\n\n\n\n\n\n\n\n\n\u8a55\u4f30\u6a5f\u5668\u5b78\u7fd2\u6f14\u7b97\u6cd5\n\u00b6\n\n\n\n\nQuestion\n\n\n\u5230\u5e95\u6a5f\u5668\u5b78\u7fd2\u5f9e\u8cc7\u6599\u88e1\u9762\u80fd\u4e0d\u80fd\u5b78\u5230\u6771\u897f\u4e26\u4e14\u9810\u6e2c\uff1f\n\n\n\n\n\n\n\n\ng:\u6a5f\u5668\u5b78\u7fd2\u5b78\u5230\u7684\u65b9\u7a0b\u5f0f \n\n\nf:\u5922\u60f3\u6c42\u51fa\u7684\u65b9\u7a0b\u5f0f\n\n\n\n\n\n\n\"\u76ee\u524d\"\u770b\u8d77\u4f86\u6a5f\u5668\u5b78\u7fd2\u7121\u6cd5\u5f9e\u8cc7\u6599\u4f86\u9810\u6e2c\u672a\u77e5\n\n\n\u96d6\u7136\u5728\u5df2\u770b\u904e\u5f97\u8cc7\u6599\u5167g=f,\u4f46\u662f\u672a\u770b\u904e\u7684\u8cc7\u6599\u5167\u7121\u6cd5\u4fdd\u8b49g=f,\u6240\u4ee5\"\u76ee\u524d\"\u53ea\u80fd\u8aaa\u6a5f\u5668\u5b78\u7fd2\u6f14\u7b97\u6cd5\u53ef\u80fd\u5b78\u4e0d\u5230\u6771\u897f\n\n\n\n\n\n\nHoeffding's inequality\u57fa\u672c\u6982\u5ff5\n\u00b6\n\n\n\u9019\u88e1\u4ee5\u5f48\u73e0\u505a\u8209\u4f8b\n\n\n\n\n\n\nSummary\n\n\n\u62bd\u4e00\u6b21\n\\mu \u8ddf \\nu\n\\mu \u8ddf \\nu\n\u8aa4\u5dee\u8d85\u904e\n\\epsilon\n\\epsilon\n\u7684\u6a5f\u7387\u5f88\u4f4e,Hoeffding's inequality\u80fd\u8aaa\u660e\u8a72\u6a5f\u7387\u6709\u591a\u4f4e\n\n\n\n\n\u7b26\u865f\u89e3\u91cb\n\u00b6\n\n\n\n\n\\mu\n\\mu\n alway unknow\n\n\nFor example ,when we count the winning percentage of the presidential election, \nIt is impossible to sample the \"entire nation\"(\n\\mu\n\\mu\n)\n\n\n\n\n\n\nN=\u62bd\u51fa\u591a\u5c11\u500b\n\n\n\\nu\n\\nu\n=\u6a58\u8272\u6a5f\u7387\u5728N\u4e2d\n\n\n\\mu\n\\mu\n=\u6a58\u8272\u7684\u6a5f\u7387\u5360\u5168\u90e8\n\u901a\u5e38\u672a\u77e5\n\u901a\u5e38\u672a\u77e5\n\n\n\\epsilon\n\\epsilon\n=\n\\nu\n\\nu\n\u8ddf\n\\mu\n\\mu\n\u7684\u8aa4\u5dee\n\n\ng:\u63a5\u8fd1\u771f\u5be6f\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578)\n\n\nf:\u5922\u60f3\u5f97\u5230\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578)\n\n\nh:g\u9078\u51fa\u7684Hypothesis\n\n\n\n\n\u56fa\u5b9a\n\\epsilon\n\\epsilon\n,\u4e00\u6b21\u62bd\u8d8a\u591a\u6a23\u672c\n\\epsilon\n\\epsilon\n\u8aa4\u5dee\n\u8aa4\u5dee\n\u6a5f\u7387\u8d8a\u5c0f\n\n\n\u56fa\u5b9aN,\n\\epsilon\n\\epsilon\n\u8aa4\u5dee\n\u8aa4\u5dee\n\u8d8a\u5927\u7684\u6a5f\u7387\u8d8a\u5c0f\n\n\n\u8b49\u660e!\u62bd\u51fa\u7684\u8d8a\u591a\nN\nN\n\u8d8a\u5927\n\\nu\n\\nu\n\u8ddf\n\\mu\n\\mu\n\u8d8a\u63a5\u8fd1\n\n\n\n\n\\nu\n\\nu\n\u548c\n\u548c\n\\mu\n\\mu\n\u5927\u6982\u5dee\u4e0d\u591a\u662f\u5c0d\u7684,\u5728\n\\epsilon\n\\epsilon\n\u5bb9\u5fcd\u8aa4\u5dee\u5167\n\n\n\n\n\n\nprobably:\u5927\u6982\n\n\n\n\n\n\napproximately:\u5dee\u4e0d\u591a\n\n\n\n\n\n\n\u7df4\u7fd2\u984c\n\u00b6\n\n\n\n\n\n\nHoeffding's inequality\u61c9\u7528\u5728\u6a5f\u5668\u5b78\u7fd2\n\u00b6\n\n\n\\nu \\implies E_{in}(h)\n\\nu \\implies E_{in}(h)\n\n\n\\mu\\implies E_{out}(h)\n\\mu\\implies E_{out}(h)\n\n\n\u7b26\u865f\u89e3\u91cb\n\u00b6\n\n\n\n\nE_{in}(h)\nE_{in}(h)\n:\u5728\u5df2\u77e5\u7684\u8cc7\u6599\u5167,\u8a72\u6f14\u7b97\u6cd5\u76ee\u524d\u72af\u932f\u7684\u6a5f\u7387(\u8d8a\u5c0f\u6e96\u78ba\u7387\u8d8a\u9ad8)\n\n\nE_{out}(h)\nE_{out}(h)\n:\u8a72\u6f14\u7b97\u6cd5\u5728\"\u5168\u90e8\"\u8cc7\u6599(\u4e0a\u5e1d\u8996\u89d2)\u5167\u72af\u932f\u7684\u6a5f\u7387(\u540c\u5e38\u672a\u77e5)\n\n\nN\nN\n:\u8cc7\u6599\u6578\u91cf\n\n\nM\nM\n:Hypothesis\u5047\u8aaa\u7684\u6578\u91cf\n\n\n\\color{red}{Bad}:E_{in}\n\\color{red}{Bad}:E_{in}\n\u8ddf\nE_{out}\nE_{out}\n\u8aa4\u5dee\u5927\u65bc\n\\epsilon\n\\epsilon\n\u7684\u60c5\u6cc1\n\n\n\n\n\n\n\u55ae\u4e00Hypothesis\n\u00b6\n\n\n\n\nSummary\n\n\n\u7528\u9014:\u78ba\u8a8d\u8a72Hypothesis\u597d\u4e0d\u597d h\n\\approx\n\\approx\nf\n\n\n\n\n\u63a5\u4e0b\u4f86\u6703\u6539\u5beb\u525b\u525b\u7684\u57fa\u672c\u6982\u5ff5,\u6539\u5beb\u6210\u9019\u500b\u516c\u5f0f\n\n\n\nHypothesis\u8aaa\u660e\u7576\u6211\u53ea\u6709\u4e00\u500bh\uff08Hypothesis\uff09,\u5f9e\u9019\u9ebc\u591a\u500b\nD\nD\n\u62bd\u5230\n\\color{red}{Bad}\n\\color{red}{Bad}\n\u7684\u6a5f\u7387\u5c0f\u65bc\u7b49\u65bc\n2e^{-2\\epsilon^{2}N}\n2e^{-2\\epsilon^{2}N}\n\n\nD_{n}\nD_{n}\n:\u6bcf\u6b21\u62bd\u51fa\u7684\u8cc7\u6599 \n\n\n\n\u986f\u793a\u6578\u5b78\n\u00b6\n\n\n\n\nCode\nimport\n \nnumpy\n \nas\n \nnp\n\n\nimport\n \nmatplotlib.pyplot\n \nas\n \nplt\n\n\nimport\n \nmatplotlib.patches\n \nas\n \nmpatches\n\n\nfig\n \n=\n \nplt\n.\nfigure\n()\n\n\nfig\n.\nsuptitle\n(\nr\n'$\\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq2e^{-2\\epsilon^{2}N}$'\n,\nfontsize\n=\n20\n,\ncolor\n=\n\"gray\"\n)\n\n\n\n\n#FIG1\n\n\nplt\n.\nsubplot\n(\n1\n,\n \n2\n,\n \n1\n)\n\n\nN\n=\n1000\n\n\ne\n=\nnp\n.\narange\n(\n0\n,\n1\n,\n0.00001\n)\n\n\ny\n=\n \n2\n*\nnp\n.\nexp\n((\n-\n2\n*\ne\n**\n2\n)\n*\nN\n)\n\n\nfor\n \ni\n \nin\n \ny\n:\n\n    \nif\n \ni\n<\n0.1\n:\n\n        \nprint\n(\ni\n)\n\n        \nplt\n.\nplot\n(\nnp\n.\narange\n(\n0\n,\n1\n,\n0.00001\n),\ni\n*\nnp\n.\nones\n(\nlen\n(\nnp\n.\narange\n(\n0\n,\n1\n,\n0.00001\n))),\n\"r-\"\n,\nlabel\n=\nr\n\"$\\mathbb{P}$<=0.1\"\n)\n\n        \nbreak\n\n\nplt\n.\nxlabel\n(\n\"\u03b5\"\n)\n\n\nplt\n.\nylabel\n(\n\"$\\mathbb{P}$\"\n)\n\n\nplt\n.\nplot\n(\ne\n,\ny\n,\ncolor\n=\n'b'\n,\nalpha\n=\n1\n,\nlabel\n=\n\"N=\"\n+\nstr\n(\nN\n))\n\n\nplt\n.\nlegend\n()\n\n\n\n#FIG2\n\n\nplt\n.\nsubplot\n(\n1\n,\n \n2\n,\n \n2\n)\n\n\ne\n=\n0.1\n\n\nN\n=\nnp\n.\narange\n(\n0\n,\n1000\n,\n1\n)\n\n\ny\n=\n \n2\n*\nnp\n.\nexp\n((\n-\n2\n*\ne\n**\n2\n)\n*\nN\n)\n\n\nfor\n \ni\n \nin\n \ny\n:\n\n    \nif\n \ni\n<\n0.1\n:\n\n        \nprint\n(\ni\n)\n\n        \nplt\n.\nplot\n(\nnp\n.\narange\n(\n0\n,\n1000\n,\n1\n),\ni\n*\nnp\n.\nones\n(\n1000\n),\n\"r-\"\n,\nlabel\n=\nr\n\"$\\mathbb{P}$<=0.1\"\n)\n\n        \nbreak\n\n\n\n\nplt\n.\nplot\n(\nN\n,\ny\n,\n\"b-\"\n,\nlabel\n=\n\"e=\"\n+\nstr\n(\ne\n))\n\n\nplt\n.\nlegend\n()\n\n\nplt\n.\nxlabel\n(\n\"N\"\n)\n\n\nplt\n.\nylabel\n(\n\"$\\mathbb{P}$\"\n)\n\n\nplt\n.\ntight_layout\n()\n\n\n\n\nplt\n.\nsubplots_adjust\n(\ntop\n=\n0.8\n)\n\n\n\nplt\n.\nshow\n()\n\n\n\n\n\u7df4\u7fd2\u984c\n\u00b6\n\n\n\n\n\u984c\u76ee\uff1a\u4f60\u7684\u670b\u53cb\u767c\u73fe\u4e00\u500b\u80a1\u5e02\u7684\u898f\u5247\"\u7576\u65e9\u4e0a\u4e0a\u6f32 \u4e0b\u5348\u5c31\u4e0b\u8dcc\",\u70ba\u4e86\u78ba\u8a8d\u9019\u689d\u898f\u5247\u4f60\u5c31\u5f9e\u904e\u53bb\u5341\u5e74\u8cc7\u6599\u88e1\u9762\u62bd\u51fa100\u7b46\u8cc7\u6599,\u767c\u73fe80\u7b46\u662f\u6b63\u78ba\u7684,\u4ec0\u9ebc\u7d50\u8ad6\u4f60\u53ef\u4ee5\u8aaa?\n\n\n1.\u85c9\u7531\u5229\u7528\u8a72\u898f\u5247\u5728\u672a\u4f86\u7684100\u5929\u8cfa\u9322,\u4f60\"\u80af\u5b9a\"\u5c07\u6703\u8b8a\u6210\u6709\u9322\u4eba(\u4e0d\u80fd\u9019\u9ebc\u80af\u5b9a)\n\n\n2.\u7576\u672a\u4f86100\u5929\u80a1\u5e02\u8d70\u52e2\u8207\u5341\u5e74\u4ee5\u4f86\u7684\u6b77\u53f2\u8cc7\u6599\u5f88\u63a5\u8fd1,\u5229\u7528\u8a72\u898f\u5247\u5728\u672a\u4f86\u7684100\u5929\u8cfa\u9322,\u4f60\"\u5f88\u53ef\u80fd\"\u6703\u8b8a\u6210\u6709\u9322\u4eba(\u6b63\u78ba)\n\n\n3.\u85c9\u7531\u5f9e20\u500b\u670b\u53cb\u88e1\u9762\u9078\u4e00\u500b\u6700\u597d\u7684\u898f\u5247,\u4f86\u7576\u4f5c\u6295\u8cc7\u672a\u4f86100\u5929\u80a1\u5e02\u7684\u65b9\u6cd5,\u4f60\u5f88\u6709\u53ef\u80fd\u8b8a\u6210\u6709\u9322\u4eba(\u932f\uff01\u56e0\u70baHypothesis\u53ea\u6709\u4e00\u500b\uff08\"\u7576\u65e9\u4e0a\u4e0a\u6f32 \u4e0b\u5348\u5c31\u4e0b\u8dcc\"\uff09\u4e0d\u80fd\u9078\u64c7)\n\n\n4.\u4f60\u80af\u5b9a\u6703\u8b8a\u6709\u9322\u4eba,\u5982\u679c\u4f60\u4ee5\u524d\u5c31\u4f7f\u7528\u8a72\u898f\u5247(\u932f \u56e0\u70ba\u4f60\u53ea\u662f\u62bd\u51fa100\u5929\u4f86\u505a\u5206\u4f48,\u641e\u4e0d\u597d\u5341\u5e74\u4f86\u7684\u8cc7\u6599\u5206\u4f48\u5f88\u4e0d\u4e00\u6a23)\n\n\n\n\n\u591a\u500bhypothesis set\n\u00b6\n\n\n\n\nSummary\n\n\n\u7528\u9014\uff1a\u7576hypothesis\u6709\u9650,\u53ef\u4ee5\u78ba\u8a8d\u8a72\u6a5f\u5668\u5b78\u7fd2\u6f14\u7b97\u6cd5\u597d\u4e0d\u597d\n\n\n\n\n\u63a8\u5c0e\n\u00b6\n\n\n\n\n\n\n\n\n\u53ef\u4ee5\u8a2d\u5b9ahypothesis set\u6709\u591a\u5c11 \u53ef\u4ee5\u8a08\u7b97\u51fa\u7576\u4f60\u7684hypothesis set\u8d8a\u5927 N\u5c31\u8981\u8d8a\u5927,\u8cc7\u6599\u624d\u6703\u6e96\u78ba\n\n\n\u986f\u793a\u6578\u5b78\n\u00b6\n\n\n\n\nCode\nimport\n \nnumpy\n \nas\n \nnp\n\n\nimport\n \nmatplotlib.pyplot\n \nas\n \nplt\n\n\nfrom\n \nmatplotlib.widgets\n \nimport\n \nSlider\n,\n \nButton\n,\n \nRadioButtons\n\n\n\nfig\n,\n \nax\n \n=\n \nplt\n.\nsubplots\n()\n\n\n#equation title\n\n\nplt\n.\nxlabel\n(\n'$\\epsilon$'\n)\n\n\nfig\n.\nsuptitle\n(\nr\n'$\\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq$2$Me^{-2\\epsilon^{2}N}$'\n,\nfontsize\n=\n20\n,\ncolor\n=\n\"black\"\n,\nalpha\n=\n0.6\n)\n\n\nplt\n.\nsubplots_adjust\n(\nleft\n=\n0.25\n,\n \nbottom\n=\n0.25\n)\n\n\nhypothesis\n=\n1\n \n#set how many hypothesis set\n\n\nx\n \n=\n \nnp\n.\narange\n(\n0.0\n,\n \n1.0\n,\n \n0.001\n)\n\n\n\na0\n \n=\n \n5\n\n\n\n\ns\n=\n2\n*\nhypothesis\n*\nnp\n.\nexp\n((\n-\n2\n*\nx\n**\n2\n)\n*\na0\n)\n\n\nl\n,\n \n=\n \nplt\n.\nplot\n(\nx\n,\n \ns\n,\n \nlw\n=\n2\n,\n \ncolor\n=\n'red'\n)\n\n\n#plt.axis([0, 1, -10, 10])\n\n\n\naxcolor\n \n=\n \n'lightgoldenrodyellow'\n\n\n\naxamp\n \n=\n \nplt\n.\naxes\n([\n0.25\n,\n \n0.09\n,\n \n0.65\n,\n \n0.03\n],\n \nfacecolor\n=\naxcolor\n)\n\n\n\n\nsamp\n \n=\n \nSlider\n(\naxamp\n,\n \n'N'\n,\n \n0.0\n,\n \n1000.0\n,\n \nvalinit\n=\na0\n)\n\n\n\n\n\nhy\n \n=\n \nplt\n.\naxes\n([\n0.25\n,\n \n0.13\n,\n \n0.65\n,\n \n0.03\n],\n \nfacecolor\n=\naxcolor\n)\n\n\n\n\nhy_ok\n \n=\n \nSlider\n(\nhy\n,\n \n'Hypothesis set(M)'\n,\n \n0.0\n,\n \n1000.0\n,\n \nvalinit\n=\nhypothesis\n)\n\n\n\n\ndef\n \nupdate\n(\nval\n):\n\n    \namp\n \n=\n \nsamp\n.\nval\n\n    \nhyy\n=\nhy_ok\n.\nval\n\n    \nl\n.\nset_ydata\n(\n2\n*\nhyy\n*\nnp\n.\nexp\n((\n-\n2\n*\nx\n**\n2\n)\n*\namp\n))\n\n    \nfig\n.\ncanvas\n.\ndraw_idle\n()\n\n\n\nsamp\n.\non_changed\n(\nupdate\n)\n\n\nhy_ok\n.\non_changed\n(\nupdate\n)\n\n\nresetax\n \n=\n \nplt\n.\naxes\n([\n0.8\n,\n \n0.025\n,\n \n0.1\n,\n \n0.04\n])\n\n\nbutton\n \n=\n \nButton\n(\nresetax\n,\n \n'Reset'\n,\n \ncolor\n=\naxcolor\n,\n \nhovercolor\n=\n'0.975'\n)\n\n\n\n\ndef\n \nreset\n(\nevent\n):\n\n    \nhy_ok\n.\nreset\n()\n\n    \nsamp\n.\nreset\n()\n\n\nbutton\n.\non_clicked\n(\nreset\n)\n\n\n\nrax\n \n=\n \nplt\n.\naxes\n([\n0.025\n,\n \n0.5\n,\n \n0.15\n,\n \n0.15\n],\n \nfacecolor\n=\naxcolor\n)\n\n\nradio\n \n=\n \nRadioButtons\n(\nrax\n,\n \n(\n'red'\n,\n \n'blue'\n,\n \n'green'\n),\n \nactive\n=\n0\n)\n\n\n\n\n\ndef\n \ncolorfunc\n(\nlabel\n):\n\n    \nl\n.\nset_color\n(\nlabel\n)\n\n    \nfig\n.\ncanvas\n.\ndraw_idle\n()\n\n\nradio\n.\non_clicked\n(\ncolorfunc\n)\n\n\n\n\nplt\n.\nshow\n()\n\n\n\n\n\n\nConclusion\n\u00b6\n\n\n\n\nNote\n\n\n\\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq\n\\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq\n2\nMe^{-2\\epsilon^{2}N}\nMe^{-2\\epsilon^{2}N}\n\nIf Machine Learning algorithm's Hypothesis is  \nfinite\n\nand \nN\nN\n is large enough ,we can say \nE_{out}(g)\\approx E_{in}(g)\nE_{out}(g)\\approx E_{in}(g)\n\nso we proof we can learning\n\n\n\n\n\n\n\n\nQuestion\n\n\nIf Hypothesis is infinite what happen?\n\n\n\n\n\n\n\u7df4\u7fd2\u984c1\n\u00b6\n\n\n\n\u984c\u76ee:\u8acb\u9078\u51fa\u932f\u8aa4\u7684\n\n\n1.\u56e0\u70ba\nx_{1}\nx_{1}\n\u8ddf\nx_{2}\nx_{2}\n\u4e0d\u540c\u6240\u4ee5\nh_{1}\nh_{1}\n\u8ddf\nh_{2}\nh_{2}\n\u4e0d\u540c\n\n\n2.\u96d6\u7136\nh_{1}\nh_{1}\n\u8ddf\nh_{3}\nh_{3}\n\u8f38\u5165\u4e0d\u5b8c\u5168\u4e00\u6a23\u4f46\u662f\u56e0\u70ba\u53ea\u5dee\u6b63\u8ca0\u865f\u6240\u4ee5\u88e1\u9762\u8cc7\u6599\u7684\u6bd4\u4f8b\u9084\u662f\u4e00\u6a23\n\n\n3.\u6309\u7167\u984c\u76ee\u4f86\u8aaahypothesis\u6709\u56db\u500b\u5e36\u5165\u516c\u5f0f\u5c31\u5982\u984c\n\n\n4.\u4f46\u662f\u7531\u65bc\u8cc7\u6599\u6b63\u8ca0\u7684\u95dc\u897f\nh_{1}=h_{3},h_{2}=h_{4}\nh_{1}=h_{3},h_{2}=h_{4}\n\u6240\u4ee5\u6263\u6389\u91cd\u8907\u7684\u90e8\u4efd,hypothesis\u5269\u4e0b\u5169\u500b\u6240\u4ee5\u8a72\u984c\u4e5f\u6b63\u78ba\uff08\n\u4e4b\u5f8c\u6703\u5229\u7528\u522a\u53bb\u91cd\u8907\u7684\u90e8\u4efd\u4f86\u6c42\u51fa\u7576\u9047\u5230\u7121\u9650\u500bhypothesis\u6642\u8a72\u600e\u9ebc\u89e3\u6c7a\n\uff09\n\n\n\n\n\u7df4\u7fd2\u984c2\n\u00b6\n\n\n\n\u984c\u76ee:\u8981\u7b26\u5408E\n\\tiny{in}\n\\tiny{in}\n\u548cE\n\\tiny{out}\n\\tiny{out}\n\u8aa4\u5dee\u8d85\u904e0.1(\n\\epsilon\n\\epsilon\n)\u7684\u6a5f\u7387\u5c0f\u65bc\u7b49\u65bc0.05(\n\\delta\n\\delta\n)hypothesis set\u6709100\u500b(M)\u6211\u7684N\u6700\u5c11\u8981\u5e7e\u500b\n\n\n\u7b54\u6848\u70ba2\n\n\n\n\n\u9047\u5230\u7121\u9650Hypothesis\u7684\u554f\u984c\n\u00b6\n\n\nPLA\u6f14\u7b97\u6cd5\u7684hypothesis set\u6709\u7121\u9650\u591a\u6240\u4ee5\u600e\u9ebc\u8fa6?\n\n\n\u56e0\u70ba\u5728\u5e73\u9762\u4e0a\u6709\u7121\u9650\u591a\u689d\u7dda\u6240\u4ee5pla\u7684hypothesis set\u6709\u7121\u9650\u591a\u500b\u90a3\u8a72\u600e\u8a08\u7b97?\n\n\u56e0\u70ba\u6709\u8a31\u591a\u91cd\u758a\u7684hypothesis set\n\n\u5e95\u4e0b\u628ahypothesis set\u7528dichotomy\u4f86\u66ff\u63db,\u56e0\u70bahypothesis set\u7121\u9650\u591a\u7121\u6cd5\u8a08\u7b97\n\n\u4ee5PLA\u8209\u4f8b:\n\n\n\n\n\n\nhypothesis set \u6240\u6709\u53ef\u80fd\u7684\u7dda(\u4ee5\u4e0a\u5716\u4f86\u8aaa\u6709\u7121\u9650\u591a\u7a2e\u4f86\u5206\u958b\u4e00\u500b\u9ede)\n\n\ndichotomy \u8cc7\u6599\u5206\u7fa4\u7684\u65b9\u6cd5(\u6709\u5169\u7a2e\u65b9\u6cd5\u4e0a\u5716\u7684\u5169\u689d\u7dda)\n\n\n\n\n\u6240\u4ee5\u8981\u7b97\u51fa\u771f\u6b63\u7684\u6210\u9577\u51fd\u6578\n\u9700\u8981\u7528\u5230\u6a5f\u7387\u7684\u77e5\u8b58\n\u9700\u8981\u7528\u5230\u6a5f\u7387\u7684\u77e5\u8b58\n\n\n\u5f71\u7247\n\n\n\n\n\n\n\\tiny{H}(N)\n\\tiny{H}(N)\n:dichotomy\n\n\n\n\n\n\nbreak point:\u7b2c\u4e00\u6b21\u6709\u767c\u751f\"\u5168\u90e8\"\u7121\u6cd5\u89e3\u6c7a\u7684N(\u53ea\u8981\u627e\u5230\u4e00\u500b\u6392\u5217\u90fd\u53ef\u4ee5\u89e3\u6c7a\u5c31\u4e0d\u662fbreakpoint)\n\n\n\n\n\n\nbreak point \u8a08\u7b97\u65b9\u6cd5\n\n\n\u4f8b\u5982perceptrons\n\n\n\n\n\n\n\u9019\u500b\u5f62\u72c0\u4e0b\u7684\u6392\u5217\u6bcf\u500b\u90fd\u53ef\u4ee5\u7528\u4e00\u689d\u7dda\u5206\u958b\u6240\u4ee5breakpoint\u4e0d\u662f3\n\n\n\n\n\n\n\n\n\u9019\u500b\u5f62\u72c0\u4e0b\u767c\u751f\u7121\u6cd5\u7528\u7dda\u5206\u958b,\u5176\u4ed6\u5f62\u72c0\u4e5f\u767c\u751f\u7121\u6cd5\u5168\u90e8\u5206\u958b\u6240\u4ee5breakpoint\u70ba4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nm\n\\tiny{H}(N)\n\\tiny{H}(N)\n<span><span class=\"MathJax_Preview\">\\tiny{H}(N)</span><script type=\"math/tex\">\\tiny{H}(N)\n=O\n$$N^{breakpoint-1}$$\n$$N^{breakpoint-1}$$\n\n\npositive rays\n\n\npositive intervals\n\n\nconvex\n\n\n2D perceptrons\n\n\n\n\n\n\n\n\n\n\nm\n\\tiny{H}(N)\n\\tiny{H}(N)\n<span><span class=\"MathJax_Preview\">\\tiny{H}(N)</span><script type=\"math/tex\">\\tiny{H}(N)\n\n\nN+1 =O\nN\nN\n\n\n\\frac{1}{2}N^2+\\frac{1}{2}N+1\n\\frac{1}{2}N^2+\\frac{1}{2}N+1\n<span><span class=\"MathJax_Preview\">\\frac{1}{2}N^2+\\frac{1}{2}N+1</span><script type=\"math/tex\">\\frac{1}{2}N^2+\\frac{1}{2}N+1\n=O\n$$N^2$$\n$$N^2$$\n\n\n2^N\n2^N\n<span><span class=\"MathJax_Preview\">2^N</span><script type=\"math/tex\">2^N\n\n\nO(N^3\nO(N^3\n<span><span class=\"MathJax_Preview\">O(N^3</span><script type=\"math/tex\">O(N^3\n)\n\n\n\n\n\n\nbreak point\n\n\n2\n\n\n3\n\n\nNone\n\n\n4\n\n\n\n\n\n\n\n\n\u6700\u5f8c\u5982\u679c\u8981\u7528dichotomy\u53d6\u4ee3hypothesis set\n\n\n\n\n\u8b49\u660e\u4e0a\u5716",
            "title": "Introduction"
        },
        {
            "location": "/Machine Learning/Introduction/#introduction",
            "text": "\u4ec0\u9ebc\u6642\u5019\u53ef\u4ee5\u4f7f\u7528\u6a5f\u5668\u5b78\u7fd2\uff1f\n 1.\u8981\u6709\u898f\u5247 2.\u4e0d\u5bb9\u6613\u5beb\u51fa\u4f86\u7684\u898f\u5247(\u8fa8\u8b58\u5716\u7247)3.\u6709\u8db3\u5920\u7684\u8cc7\u6599\n  \u6a5f\u5668\u5b78\u7fd2\u4f5c\u6cd5\uff1f\n  \u5f9e\u8cc7\u6599\u51fa\u767c\u53bb\u5b78\u7fd2",
            "title": "Introduction"
        },
        {
            "location": "/Machine Learning/Introduction/#learning-model",
            "text": "\u76ee\u6a19\uff1a\u5f9eA\u88e1\u9762\u5f88\u591a\u500bH\u4e2d\u9078\u4e00\u500b\u4f86\u4ee3\u8868g,\u5e0c\u671bg\u8d8a\u63a5\u8fd1f\n\u53e6\u4e00\u7a2e\u89e3\u91cb\u65b9\u6cd5\uff1a\u5728\u65b9\u7a0b\u5f0f\u88e1\u9762,\u6709H\u500b\u89e3,g\u5c31\u662f\u9078\u5230\u6700\u597d\u7684\u89e3    D:\u8ddff\u6709\u95dc\u7684\u8cc7\u6599   A:\u6a5f\u5668\u5b78\u7fd2\u7684\u6f14\u7b97\u6cd5   H:A\u6f14\u7b97\u6cd5\u88e1\u9762\u6709\u5f88\u591a\u500b\u5047\u8aaaH  g:\u63a5\u8fd1\u771f\u5be6f\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578)   f:\u5922\u60f3\u5f97\u5230\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578)    Example  D:your data input to x \nA: machine learning algorithm is y=ax  \nH:H\u2208 \\mathbb{Q} \\mathbb{Q}  all possible in this algorithm {y=0.3x,y=6x,y=6.7x...} \ng: our machine learning get answer y=2.9999x it close to f \nf:we want to get this function y=3x",
            "title": "Learning Model"
        },
        {
            "location": "/Machine Learning/Introduction/#types-of-machine-learning",
            "text": "",
            "title": "Types of Machine Learning"
        },
        {
            "location": "/Machine Learning/Introduction/#output-space",
            "text": "(\u8981\u554f\u4ec0\u9ebc\u554f\u984c)     Binary Classification  Multiclass classification  Regression  Structured Learning",
            "title": "Output Space"
        },
        {
            "location": "/Machine Learning/Introduction/#data-label",
            "text": "(\u62ff\u5230\u4e0d\u540c\u6a19\u8a18\u7684\u8cc7\u6599,\u8981\u600e\u8655\u7406)     Supervised  Semi-supervised      Sample:Classification      \u5df2\u7d93\u6a19\u8a18\u597d\u8cc7\u6599         Unsupervised  Reinforcement Learning (\u589e\u5f37\u5f0f\u5b78\u7fd2)      Sample: Clustering  clustering(\u5206\u7fa4)density estimation:\u54ea\u4e9b\u5730\u65b9\u6bd4\u8f03\u7a20\u5bc6\u61c9\u7528ex.\u54ea\u88e1\u6bd4\u8f03\u5e38\u767c\u751f\u4e8b\u6545outlier detection:\u627e\u51fa\u7570\u5e38\u7684\u8cc7\u6599,\u56e0\u70ba\u7570\u5e38\u8cc7\u6599\u5f88\u5c11  \u8ddf\u8a13\u7df4\u5bf5\u7269\u4e00\u6a23,\u5c0d\u7d66\u734e\u52f5,\u932f\u7d66\u61f2\u7f70",
            "title": "Data Label"
        },
        {
            "location": "/Machine Learning/Introduction/#protocol",
            "text": "\u8f38\u5165\u8cc7\u6599\u7684\u65b9\u6cd5 f \\implies (x_{n},y_{n}) f \\implies (x_{n},y_{n})     batch  Online  active      \u6210\u6279\u7684\u8cc7\u6599\u4f86\u5b78\u7fd2  \u4e00\u7b46\u4e00\u7b46\u8cc7\u6599\u4f86\u5b78\u7fd2,\u9047\u5230\u932f\u8aa4\u5728\u6539\u6b63ex.PLA,Reinforcement Learning  \u6a5f\u5668\u81ea\u5df1\u554f\u554f\u984c,\u7576\u8cc7\u6599\u5f88\u5c11\u6216\u5f88\u8cb4\u53ef\u4ee5\u4f7f\u7528,\u4e5f\u5e0c\u671b\u6a5f\u5668\u5b78\u7fd2\u901f\u5ea6\u52a0\u5feb\u8ddf\u4eba\u4e00\u6a23ex.\u6a5f\u5668\u81ea\u5df1\u5beb\u4e00\u500b\u6578\u5b57,\u53cd\u904e\u4f86\u554f\u4eba\u4f86\u5b78\u7fd2",
            "title": "Protocol"
        },
        {
            "location": "/Machine Learning/Introduction/#input-space",
            "text": "\u8cc7\u6599\u7a2e\u985e \\mathcal{X} \\mathcal{X} \n\u8d8a\u62bd\u8c61\u7684\u8cc7\u6599\u96fb\u8166\u8d8a\u96e3\u5b78\u7fd2   Sample  Mnist\u4f7f\u7528Multilayer perceptron \u662f\u4f7f\u7528raw pixel\u8cc7\u6599 \u6e96\u78ba\u5ea691% \nMnist\u4f7f\u7528CNN\u6e96\u78ba\u5ea6\u5927\u7d0498~99% \n\u7531\u6b64\u53ef\u77e5\u7576Raw\u7684\u8cc7\u6599\u8b8a\u6210Concrete\u96fb\u8166\u5c31\u80fd\u5b78\u5f97\u8d8a\u4f86\u8d8a\u597d      Concrete(\u5305\u542b\u4eba\u985e\u667a\u6167)  Raw  abstract(\u6700\u62bd\u8c61)      \u8cc7\u6599\u88e1\u9762\u6709\u4eba\u985e\u7684\u667a\u6167,\u6709\u9810\u5148\u8655\u7406\u7684\u8cc7\u6599,\u7bc4\u4f8b:\u8fa8\u8b581\u8ddf5 \u7528\u4eba\u8166\u5beb\u4e0b\u898f\u5247\u5230\u5e95\u9019\u5f35\u5716\u6709\u6c92\u6709\u5c0d\u7a31\u6216\u662f\u5bc6\u5ea6\u5982\u4f55  \u539f\u59cb\u7684\u8cc7\u6599,\u97f3\u8a0a,bit,pixel,\u7bc4\u4f8b:\u76f4\u63a5\u8f38\u5165pixel,\u4f46pixel\u6c92\u6709\u4eba\u985e\u667a\u6167\u53ea\u662f\u55ae\u7d14\u7684\u6578\u64da  \u62bd\u8c61\u7684\u8cc7\u6599ex.\u4f7f\u7528\u8005id\u7de8\u865f",
            "title": "Input Space"
        },
        {
            "location": "/Machine Learning/Introduction/#_1",
            "text": "Question  \u5230\u5e95\u6a5f\u5668\u5b78\u7fd2\u5f9e\u8cc7\u6599\u88e1\u9762\u80fd\u4e0d\u80fd\u5b78\u5230\u6771\u897f\u4e26\u4e14\u9810\u6e2c\uff1f     g:\u6a5f\u5668\u5b78\u7fd2\u5b78\u5230\u7684\u65b9\u7a0b\u5f0f   f:\u5922\u60f3\u6c42\u51fa\u7684\u65b9\u7a0b\u5f0f    \"\u76ee\u524d\"\u770b\u8d77\u4f86\u6a5f\u5668\u5b78\u7fd2\u7121\u6cd5\u5f9e\u8cc7\u6599\u4f86\u9810\u6e2c\u672a\u77e5  \u96d6\u7136\u5728\u5df2\u770b\u904e\u5f97\u8cc7\u6599\u5167g=f,\u4f46\u662f\u672a\u770b\u904e\u7684\u8cc7\u6599\u5167\u7121\u6cd5\u4fdd\u8b49g=f,\u6240\u4ee5\"\u76ee\u524d\"\u53ea\u80fd\u8aaa\u6a5f\u5668\u5b78\u7fd2\u6f14\u7b97\u6cd5\u53ef\u80fd\u5b78\u4e0d\u5230\u6771\u897f",
            "title": "\u8a55\u4f30\u6a5f\u5668\u5b78\u7fd2\u6f14\u7b97\u6cd5"
        },
        {
            "location": "/Machine Learning/Introduction/#hoeffdings-inequality",
            "text": "\u9019\u88e1\u4ee5\u5f48\u73e0\u505a\u8209\u4f8b    Summary  \u62bd\u4e00\u6b21 \\mu \u8ddf \\nu \\mu \u8ddf \\nu \u8aa4\u5dee\u8d85\u904e \\epsilon \\epsilon \u7684\u6a5f\u7387\u5f88\u4f4e,Hoeffding's inequality\u80fd\u8aaa\u660e\u8a72\u6a5f\u7387\u6709\u591a\u4f4e",
            "title": "Hoeffding's inequality\u57fa\u672c\u6982\u5ff5"
        },
        {
            "location": "/Machine Learning/Introduction/#_2",
            "text": "\\mu \\mu  alway unknow  For example ,when we count the winning percentage of the presidential election, \nIt is impossible to sample the \"entire nation\"( \\mu \\mu )    N=\u62bd\u51fa\u591a\u5c11\u500b  \\nu \\nu =\u6a58\u8272\u6a5f\u7387\u5728N\u4e2d  \\mu \\mu =\u6a58\u8272\u7684\u6a5f\u7387\u5360\u5168\u90e8 \u901a\u5e38\u672a\u77e5 \u901a\u5e38\u672a\u77e5  \\epsilon \\epsilon = \\nu \\nu \u8ddf \\mu \\mu \u7684\u8aa4\u5dee  g:\u63a5\u8fd1\u771f\u5be6f\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578)  f:\u5922\u60f3\u5f97\u5230\u7684\u6f14\u7b97\u6cd5(\u51fd\u6578)  h:g\u9078\u51fa\u7684Hypothesis   \u56fa\u5b9a \\epsilon \\epsilon ,\u4e00\u6b21\u62bd\u8d8a\u591a\u6a23\u672c \\epsilon \\epsilon \u8aa4\u5dee \u8aa4\u5dee \u6a5f\u7387\u8d8a\u5c0f  \u56fa\u5b9aN, \\epsilon \\epsilon \u8aa4\u5dee \u8aa4\u5dee \u8d8a\u5927\u7684\u6a5f\u7387\u8d8a\u5c0f  \u8b49\u660e!\u62bd\u51fa\u7684\u8d8a\u591a N N \u8d8a\u5927 \\nu \\nu \u8ddf \\mu \\mu \u8d8a\u63a5\u8fd1   \\nu \\nu \u548c \u548c \\mu \\mu \u5927\u6982\u5dee\u4e0d\u591a\u662f\u5c0d\u7684,\u5728 \\epsilon \\epsilon \u5bb9\u5fcd\u8aa4\u5dee\u5167    probably:\u5927\u6982    approximately:\u5dee\u4e0d\u591a",
            "title": "\u7b26\u865f\u89e3\u91cb"
        },
        {
            "location": "/Machine Learning/Introduction/#_3",
            "text": "",
            "title": "\u7df4\u7fd2\u984c"
        },
        {
            "location": "/Machine Learning/Introduction/#hoeffdings-inequality_1",
            "text": "\\nu \\implies E_{in}(h) \\nu \\implies E_{in}(h)  \\mu\\implies E_{out}(h) \\mu\\implies E_{out}(h)",
            "title": "Hoeffding's inequality\u61c9\u7528\u5728\u6a5f\u5668\u5b78\u7fd2"
        },
        {
            "location": "/Machine Learning/Introduction/#_4",
            "text": "E_{in}(h) E_{in}(h) :\u5728\u5df2\u77e5\u7684\u8cc7\u6599\u5167,\u8a72\u6f14\u7b97\u6cd5\u76ee\u524d\u72af\u932f\u7684\u6a5f\u7387(\u8d8a\u5c0f\u6e96\u78ba\u7387\u8d8a\u9ad8)  E_{out}(h) E_{out}(h) :\u8a72\u6f14\u7b97\u6cd5\u5728\"\u5168\u90e8\"\u8cc7\u6599(\u4e0a\u5e1d\u8996\u89d2)\u5167\u72af\u932f\u7684\u6a5f\u7387(\u540c\u5e38\u672a\u77e5)  N N :\u8cc7\u6599\u6578\u91cf  M M :Hypothesis\u5047\u8aaa\u7684\u6578\u91cf  \\color{red}{Bad}:E_{in} \\color{red}{Bad}:E_{in} \u8ddf E_{out} E_{out} \u8aa4\u5dee\u5927\u65bc \\epsilon \\epsilon \u7684\u60c5\u6cc1",
            "title": "\u7b26\u865f\u89e3\u91cb"
        },
        {
            "location": "/Machine Learning/Introduction/#hypothesis",
            "text": "Summary  \u7528\u9014:\u78ba\u8a8d\u8a72Hypothesis\u597d\u4e0d\u597d h \\approx \\approx f   \u63a5\u4e0b\u4f86\u6703\u6539\u5beb\u525b\u525b\u7684\u57fa\u672c\u6982\u5ff5,\u6539\u5beb\u6210\u9019\u500b\u516c\u5f0f  Hypothesis\u8aaa\u660e\u7576\u6211\u53ea\u6709\u4e00\u500bh\uff08Hypothesis\uff09,\u5f9e\u9019\u9ebc\u591a\u500b D D \u62bd\u5230 \\color{red}{Bad} \\color{red}{Bad} \u7684\u6a5f\u7387\u5c0f\u65bc\u7b49\u65bc 2e^{-2\\epsilon^{2}N} 2e^{-2\\epsilon^{2}N}  D_{n} D_{n} :\u6bcf\u6b21\u62bd\u51fa\u7684\u8cc7\u6599",
            "title": "\u55ae\u4e00Hypothesis"
        },
        {
            "location": "/Machine Learning/Introduction/#_5",
            "text": "Code import   numpy   as   np  import   matplotlib.pyplot   as   plt  import   matplotlib.patches   as   mpatches  fig   =   plt . figure ()  fig . suptitle ( r '$\\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq2e^{-2\\epsilon^{2}N}$' , fontsize = 20 , color = \"gray\" )  #FIG1  plt . subplot ( 1 ,   2 ,   1 )  N = 1000  e = np . arange ( 0 , 1 , 0.00001 )  y =   2 * np . exp (( - 2 * e ** 2 ) * N )  for   i   in   y : \n     if   i < 0.1 : \n         print ( i ) \n         plt . plot ( np . arange ( 0 , 1 , 0.00001 ), i * np . ones ( len ( np . arange ( 0 , 1 , 0.00001 ))), \"r-\" , label = r \"$\\mathbb{P}$<=0.1\" ) \n         break  plt . xlabel ( \"\u03b5\" )  plt . ylabel ( \"$\\mathbb{P}$\" )  plt . plot ( e , y , color = 'b' , alpha = 1 , label = \"N=\" + str ( N ))  plt . legend ()  #FIG2  plt . subplot ( 1 ,   2 ,   2 )  e = 0.1  N = np . arange ( 0 , 1000 , 1 )  y =   2 * np . exp (( - 2 * e ** 2 ) * N )  for   i   in   y : \n     if   i < 0.1 : \n         print ( i ) \n         plt . plot ( np . arange ( 0 , 1000 , 1 ), i * np . ones ( 1000 ), \"r-\" , label = r \"$\\mathbb{P}$<=0.1\" ) \n         break  plt . plot ( N , y , \"b-\" , label = \"e=\" + str ( e ))  plt . legend ()  plt . xlabel ( \"N\" )  plt . ylabel ( \"$\\mathbb{P}$\" )  plt . tight_layout ()  plt . subplots_adjust ( top = 0.8 )  plt . show ()",
            "title": "\u986f\u793a\u6578\u5b78"
        },
        {
            "location": "/Machine Learning/Introduction/#_6",
            "text": "\u984c\u76ee\uff1a\u4f60\u7684\u670b\u53cb\u767c\u73fe\u4e00\u500b\u80a1\u5e02\u7684\u898f\u5247\"\u7576\u65e9\u4e0a\u4e0a\u6f32 \u4e0b\u5348\u5c31\u4e0b\u8dcc\",\u70ba\u4e86\u78ba\u8a8d\u9019\u689d\u898f\u5247\u4f60\u5c31\u5f9e\u904e\u53bb\u5341\u5e74\u8cc7\u6599\u88e1\u9762\u62bd\u51fa100\u7b46\u8cc7\u6599,\u767c\u73fe80\u7b46\u662f\u6b63\u78ba\u7684,\u4ec0\u9ebc\u7d50\u8ad6\u4f60\u53ef\u4ee5\u8aaa?  1.\u85c9\u7531\u5229\u7528\u8a72\u898f\u5247\u5728\u672a\u4f86\u7684100\u5929\u8cfa\u9322,\u4f60\"\u80af\u5b9a\"\u5c07\u6703\u8b8a\u6210\u6709\u9322\u4eba(\u4e0d\u80fd\u9019\u9ebc\u80af\u5b9a)  2.\u7576\u672a\u4f86100\u5929\u80a1\u5e02\u8d70\u52e2\u8207\u5341\u5e74\u4ee5\u4f86\u7684\u6b77\u53f2\u8cc7\u6599\u5f88\u63a5\u8fd1,\u5229\u7528\u8a72\u898f\u5247\u5728\u672a\u4f86\u7684100\u5929\u8cfa\u9322,\u4f60\"\u5f88\u53ef\u80fd\"\u6703\u8b8a\u6210\u6709\u9322\u4eba(\u6b63\u78ba)  3.\u85c9\u7531\u5f9e20\u500b\u670b\u53cb\u88e1\u9762\u9078\u4e00\u500b\u6700\u597d\u7684\u898f\u5247,\u4f86\u7576\u4f5c\u6295\u8cc7\u672a\u4f86100\u5929\u80a1\u5e02\u7684\u65b9\u6cd5,\u4f60\u5f88\u6709\u53ef\u80fd\u8b8a\u6210\u6709\u9322\u4eba(\u932f\uff01\u56e0\u70baHypothesis\u53ea\u6709\u4e00\u500b\uff08\"\u7576\u65e9\u4e0a\u4e0a\u6f32 \u4e0b\u5348\u5c31\u4e0b\u8dcc\"\uff09\u4e0d\u80fd\u9078\u64c7)  4.\u4f60\u80af\u5b9a\u6703\u8b8a\u6709\u9322\u4eba,\u5982\u679c\u4f60\u4ee5\u524d\u5c31\u4f7f\u7528\u8a72\u898f\u5247(\u932f \u56e0\u70ba\u4f60\u53ea\u662f\u62bd\u51fa100\u5929\u4f86\u505a\u5206\u4f48,\u641e\u4e0d\u597d\u5341\u5e74\u4f86\u7684\u8cc7\u6599\u5206\u4f48\u5f88\u4e0d\u4e00\u6a23)",
            "title": "\u7df4\u7fd2\u984c"
        },
        {
            "location": "/Machine Learning/Introduction/#hypothesis-set",
            "text": "Summary  \u7528\u9014\uff1a\u7576hypothesis\u6709\u9650,\u53ef\u4ee5\u78ba\u8a8d\u8a72\u6a5f\u5668\u5b78\u7fd2\u6f14\u7b97\u6cd5\u597d\u4e0d\u597d",
            "title": "\u591a\u500bhypothesis set"
        },
        {
            "location": "/Machine Learning/Introduction/#_7",
            "text": "\u53ef\u4ee5\u8a2d\u5b9ahypothesis set\u6709\u591a\u5c11 \u53ef\u4ee5\u8a08\u7b97\u51fa\u7576\u4f60\u7684hypothesis set\u8d8a\u5927 N\u5c31\u8981\u8d8a\u5927,\u8cc7\u6599\u624d\u6703\u6e96\u78ba",
            "title": "\u63a8\u5c0e"
        },
        {
            "location": "/Machine Learning/Introduction/#_8",
            "text": "Code import   numpy   as   np  import   matplotlib.pyplot   as   plt  from   matplotlib.widgets   import   Slider ,   Button ,   RadioButtons  fig ,   ax   =   plt . subplots ()  #equation title  plt . xlabel ( '$\\epsilon$' )  fig . suptitle ( r '$\\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq$2$Me^{-2\\epsilon^{2}N}$' , fontsize = 20 , color = \"black\" , alpha = 0.6 )  plt . subplots_adjust ( left = 0.25 ,   bottom = 0.25 )  hypothesis = 1   #set how many hypothesis set  x   =   np . arange ( 0.0 ,   1.0 ,   0.001 )  a0   =   5  s = 2 * hypothesis * np . exp (( - 2 * x ** 2 ) * a0 )  l ,   =   plt . plot ( x ,   s ,   lw = 2 ,   color = 'red' )  #plt.axis([0, 1, -10, 10])  axcolor   =   'lightgoldenrodyellow'  axamp   =   plt . axes ([ 0.25 ,   0.09 ,   0.65 ,   0.03 ],   facecolor = axcolor )  samp   =   Slider ( axamp ,   'N' ,   0.0 ,   1000.0 ,   valinit = a0 )  hy   =   plt . axes ([ 0.25 ,   0.13 ,   0.65 ,   0.03 ],   facecolor = axcolor )  hy_ok   =   Slider ( hy ,   'Hypothesis set(M)' ,   0.0 ,   1000.0 ,   valinit = hypothesis )  def   update ( val ): \n     amp   =   samp . val \n     hyy = hy_ok . val \n     l . set_ydata ( 2 * hyy * np . exp (( - 2 * x ** 2 ) * amp )) \n     fig . canvas . draw_idle ()  samp . on_changed ( update )  hy_ok . on_changed ( update )  resetax   =   plt . axes ([ 0.8 ,   0.025 ,   0.1 ,   0.04 ])  button   =   Button ( resetax ,   'Reset' ,   color = axcolor ,   hovercolor = '0.975' )  def   reset ( event ): \n     hy_ok . reset () \n     samp . reset ()  button . on_clicked ( reset )  rax   =   plt . axes ([ 0.025 ,   0.5 ,   0.15 ,   0.15 ],   facecolor = axcolor )  radio   =   RadioButtons ( rax ,   ( 'red' ,   'blue' ,   'green' ),   active = 0 )  def   colorfunc ( label ): \n     l . set_color ( label ) \n     fig . canvas . draw_idle ()  radio . on_clicked ( colorfunc )  plt . show ()",
            "title": "\u986f\u793a\u6578\u5b78"
        },
        {
            "location": "/Machine Learning/Introduction/#conclusion",
            "text": "Note  \\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq \\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\\epsilon]\\leq 2 Me^{-2\\epsilon^{2}N} Me^{-2\\epsilon^{2}N} \nIf Machine Learning algorithm's Hypothesis is   finite \nand  N N  is large enough ,we can say  E_{out}(g)\\approx E_{in}(g) E_{out}(g)\\approx E_{in}(g) \nso we proof we can learning     Question  If Hypothesis is infinite what happen?",
            "title": "Conclusion"
        },
        {
            "location": "/Machine Learning/Introduction/#1",
            "text": "\u984c\u76ee:\u8acb\u9078\u51fa\u932f\u8aa4\u7684  1.\u56e0\u70ba x_{1} x_{1} \u8ddf x_{2} x_{2} \u4e0d\u540c\u6240\u4ee5 h_{1} h_{1} \u8ddf h_{2} h_{2} \u4e0d\u540c  2.\u96d6\u7136 h_{1} h_{1} \u8ddf h_{3} h_{3} \u8f38\u5165\u4e0d\u5b8c\u5168\u4e00\u6a23\u4f46\u662f\u56e0\u70ba\u53ea\u5dee\u6b63\u8ca0\u865f\u6240\u4ee5\u88e1\u9762\u8cc7\u6599\u7684\u6bd4\u4f8b\u9084\u662f\u4e00\u6a23  3.\u6309\u7167\u984c\u76ee\u4f86\u8aaahypothesis\u6709\u56db\u500b\u5e36\u5165\u516c\u5f0f\u5c31\u5982\u984c  4.\u4f46\u662f\u7531\u65bc\u8cc7\u6599\u6b63\u8ca0\u7684\u95dc\u897f h_{1}=h_{3},h_{2}=h_{4} h_{1}=h_{3},h_{2}=h_{4} \u6240\u4ee5\u6263\u6389\u91cd\u8907\u7684\u90e8\u4efd,hypothesis\u5269\u4e0b\u5169\u500b\u6240\u4ee5\u8a72\u984c\u4e5f\u6b63\u78ba\uff08 \u4e4b\u5f8c\u6703\u5229\u7528\u522a\u53bb\u91cd\u8907\u7684\u90e8\u4efd\u4f86\u6c42\u51fa\u7576\u9047\u5230\u7121\u9650\u500bhypothesis\u6642\u8a72\u600e\u9ebc\u89e3\u6c7a \uff09",
            "title": "\u7df4\u7fd2\u984c1"
        },
        {
            "location": "/Machine Learning/Introduction/#2",
            "text": "\u984c\u76ee:\u8981\u7b26\u5408E \\tiny{in} \\tiny{in} \u548cE \\tiny{out} \\tiny{out} \u8aa4\u5dee\u8d85\u904e0.1( \\epsilon \\epsilon )\u7684\u6a5f\u7387\u5c0f\u65bc\u7b49\u65bc0.05( \\delta \\delta )hypothesis set\u6709100\u500b(M)\u6211\u7684N\u6700\u5c11\u8981\u5e7e\u500b  \u7b54\u6848\u70ba2",
            "title": "\u7df4\u7fd2\u984c2"
        },
        {
            "location": "/Machine Learning/Introduction/#hypothesis_1",
            "text": "PLA\u6f14\u7b97\u6cd5\u7684hypothesis set\u6709\u7121\u9650\u591a\u6240\u4ee5\u600e\u9ebc\u8fa6?  \u56e0\u70ba\u5728\u5e73\u9762\u4e0a\u6709\u7121\u9650\u591a\u689d\u7dda\u6240\u4ee5pla\u7684hypothesis set\u6709\u7121\u9650\u591a\u500b\u90a3\u8a72\u600e\u8a08\u7b97? \n\u56e0\u70ba\u6709\u8a31\u591a\u91cd\u758a\u7684hypothesis set \n\u5e95\u4e0b\u628ahypothesis set\u7528dichotomy\u4f86\u66ff\u63db,\u56e0\u70bahypothesis set\u7121\u9650\u591a\u7121\u6cd5\u8a08\u7b97 \n\u4ee5PLA\u8209\u4f8b:    hypothesis set \u6240\u6709\u53ef\u80fd\u7684\u7dda(\u4ee5\u4e0a\u5716\u4f86\u8aaa\u6709\u7121\u9650\u591a\u7a2e\u4f86\u5206\u958b\u4e00\u500b\u9ede)  dichotomy \u8cc7\u6599\u5206\u7fa4\u7684\u65b9\u6cd5(\u6709\u5169\u7a2e\u65b9\u6cd5\u4e0a\u5716\u7684\u5169\u689d\u7dda)   \u6240\u4ee5\u8981\u7b97\u51fa\u771f\u6b63\u7684\u6210\u9577\u51fd\u6578 \u9700\u8981\u7528\u5230\u6a5f\u7387\u7684\u77e5\u8b58 \u9700\u8981\u7528\u5230\u6a5f\u7387\u7684\u77e5\u8b58  \u5f71\u7247    \\tiny{H}(N) \\tiny{H}(N) :dichotomy    break point:\u7b2c\u4e00\u6b21\u6709\u767c\u751f\"\u5168\u90e8\"\u7121\u6cd5\u89e3\u6c7a\u7684N(\u53ea\u8981\u627e\u5230\u4e00\u500b\u6392\u5217\u90fd\u53ef\u4ee5\u89e3\u6c7a\u5c31\u4e0d\u662fbreakpoint)    break point \u8a08\u7b97\u65b9\u6cd5  \u4f8b\u5982perceptrons    \u9019\u500b\u5f62\u72c0\u4e0b\u7684\u6392\u5217\u6bcf\u500b\u90fd\u53ef\u4ee5\u7528\u4e00\u689d\u7dda\u5206\u958b\u6240\u4ee5breakpoint\u4e0d\u662f3     \u9019\u500b\u5f62\u72c0\u4e0b\u767c\u751f\u7121\u6cd5\u7528\u7dda\u5206\u958b,\u5176\u4ed6\u5f62\u72c0\u4e5f\u767c\u751f\u7121\u6cd5\u5168\u90e8\u5206\u958b\u6240\u4ee5breakpoint\u70ba4        m \\tiny{H}(N) \\tiny{H}(N) <span><span class=\"MathJax_Preview\">\\tiny{H}(N)</span><script type=\"math/tex\">\\tiny{H}(N) =O $$N^{breakpoint-1}$$ $$N^{breakpoint-1}$$  positive rays  positive intervals  convex  2D perceptrons      m \\tiny{H}(N) \\tiny{H}(N) <span><span class=\"MathJax_Preview\">\\tiny{H}(N)</span><script type=\"math/tex\">\\tiny{H}(N)  N+1 =O N N  \\frac{1}{2}N^2+\\frac{1}{2}N+1 \\frac{1}{2}N^2+\\frac{1}{2}N+1 <span><span class=\"MathJax_Preview\">\\frac{1}{2}N^2+\\frac{1}{2}N+1</span><script type=\"math/tex\">\\frac{1}{2}N^2+\\frac{1}{2}N+1 =O $$N^2$$ $$N^2$$  2^N 2^N <span><span class=\"MathJax_Preview\">2^N</span><script type=\"math/tex\">2^N  O(N^3 O(N^3 <span><span class=\"MathJax_Preview\">O(N^3</span><script type=\"math/tex\">O(N^3 )    break point  2  3  None  4     \u6700\u5f8c\u5982\u679c\u8981\u7528dichotomy\u53d6\u4ee3hypothesis set   \u8b49\u660e\u4e0a\u5716",
            "title": "\u9047\u5230\u7121\u9650Hypothesis\u7684\u554f\u984c"
        },
        {
            "location": "/Machine Learning/Neural Networks/Introduction/",
            "text": "Introduction\n\u00b6",
            "title": "Introduction"
        },
        {
            "location": "/Machine Learning/Neural Networks/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/Machine Learning/Neural Networks/CNN/CNN/",
            "text": "\u5377\u7a4d\u795e\u7d93\u7db2\u8def\n\u00b6\n\n\n\u63a5\u4e0b\u4f86\u7684\u7b46\u8a18\u53c3\u8003\u4e86\u4ee5\u4e0b\u7684\u7db2\u8def\u8cc7\u6e90:\n\nhttp://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/\n\n\nhttp://cs231n.github.io/convolutional-networks/#pool\n\n\nhttps://chtseng.wordpress.com/2017/09/12/%E5%88%9D%E6%8E%A2%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/",
            "title": "CNN"
        },
        {
            "location": "/Machine Learning/Neural Networks/CNN/CNN/#_1",
            "text": "\u63a5\u4e0b\u4f86\u7684\u7b46\u8a18\u53c3\u8003\u4e86\u4ee5\u4e0b\u7684\u7db2\u8def\u8cc7\u6e90: http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/  http://cs231n.github.io/convolutional-networks/#pool  https://chtseng.wordpress.com/2017/09/12/%E5%88%9D%E6%8E%A2%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/",
            "title": "\u5377\u7a4d\u795e\u7d93\u7db2\u8def"
        },
        {
            "location": "/Machine Learning/Neural Networks/CNN/sample/Devanagari Handwritten Character/",
            "text": "Devanagari Handwritten Character\n\u00b6\n\n\n\u8cc7\u6599\u96c6\u4ecb\u7d39\n\u00b6\n\n\n\u68b5\u8a9e36\u500b\u57fa\u672c\u5b57\u6bcd+10\u500b\u6578\u5b57\n\u5b9a\u7fa9\n['digit_4', 'character_29_waw', 'character_20_na', 'character_33_ha', 'character_5_kna', 'digit_6', 'character_18_da', 'character_9_jha', 'character_36_gya', 'character_16_tabala', 'character_10_yna', 'character_34_chhya', 'digit_7', 'character_11_taamatar', 'character_17_tha', 'digit_3', 'digit_2', 'character_25_ma', 'character_30_motosaw', 'digit_0', 'character_8_ja', 'character_13_daa', 'character_15_adna', 'character_3_ga', 'digit_8', 'character_28_la', 'character_6_cha', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_1_ka', 'character_7_chha', 'digit_1', 'character_14_dhaa', 'character_21_pa', 'character_22_pha', 'character_35_tra', 'character_12_thaa', 'character_4_gha', 'character_23_ba', 'character_2_kha', 'digit_5', 'character_27_ra', 'character_19_dha', 'digit_9', 'character_26_yaw', 'character_24_bha']\n\n\n\uff01\uff01\uff01 sample\n    [0,.......1]\u70bacharacter_24_bha\n\n\n\u53c3\u8003(\u5408\u5beb\u8ddf\u6578\u5b57\u7684\u90e8\u4efd)\n\n\n\u5929\u57ce\u6587\u8cc7\u6599\u96c6\u4e0b\u8f09\uff08uci\uff09",
            "title": "Devanagari Handwritten Character"
        },
        {
            "location": "/Machine Learning/Neural Networks/CNN/sample/Devanagari Handwritten Character/#devanagari-handwritten-character",
            "text": "",
            "title": "Devanagari Handwritten Character"
        },
        {
            "location": "/Machine Learning/Neural Networks/CNN/sample/Devanagari Handwritten Character/#_1",
            "text": "\u68b5\u8a9e36\u500b\u57fa\u672c\u5b57\u6bcd+10\u500b\u6578\u5b57\n\u5b9a\u7fa9\n['digit_4', 'character_29_waw', 'character_20_na', 'character_33_ha', 'character_5_kna', 'digit_6', 'character_18_da', 'character_9_jha', 'character_36_gya', 'character_16_tabala', 'character_10_yna', 'character_34_chhya', 'digit_7', 'character_11_taamatar', 'character_17_tha', 'digit_3', 'digit_2', 'character_25_ma', 'character_30_motosaw', 'digit_0', 'character_8_ja', 'character_13_daa', 'character_15_adna', 'character_3_ga', 'digit_8', 'character_28_la', 'character_6_cha', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_1_ka', 'character_7_chha', 'digit_1', 'character_14_dhaa', 'character_21_pa', 'character_22_pha', 'character_35_tra', 'character_12_thaa', 'character_4_gha', 'character_23_ba', 'character_2_kha', 'digit_5', 'character_27_ra', 'character_19_dha', 'digit_9', 'character_26_yaw', 'character_24_bha']  \uff01\uff01\uff01 sample\n    [0,.......1]\u70bacharacter_24_bha  \u53c3\u8003(\u5408\u5beb\u8ddf\u6578\u5b57\u7684\u90e8\u4efd)  \u5929\u57ce\u6587\u8cc7\u6599\u96c6\u4e0b\u8f09\uff08uci\uff09",
            "title": "\u8cc7\u6599\u96c6\u4ecb\u7d39"
        },
        {
            "location": "/Machine Learning/Neural Networks/Multilayer perceptron/MLP(Regression)/",
            "text": "MLP(Regression)\n\u00b6\n\n\nType Of Machine Learning\n\u00b6\n\n\n\n\n\n\n\n\nOutput Space\n\n\nData Label\n\n\nProtocol\n\n\nInput Space\n\n\n\n\n\n\n\n\n\n\nBinary Classification\n\n\nSupervised\n\n\nOnline\n\n\nRaw\n\n\n\n\n\n\n\n\n\n\u8a72\u7bc4\u4f8b\u7684\u7d50\u69cb\n\n\n\n\n\n\n\n\n\n\nInfo\n\n\nIn this sample is Fully connected three-layered MLP network with 150 neurons in the hidden layer.\n\n\n\n\n\n\nFull connected:\u5168\u9023\u63a5\u5c64\n\n\nMLP (\u591a\u5c64\u611f\u77e5\u5668):\u52a0\u4e0aactivation function\u8ddf\u53cd\u5411\u50b3\u905e\u6f14\u7b97\u6cd5\n\n\n\n\nCode\nfrom\n \n__future__\n \nimport\n \nprint_function\n\n\nimport\n \ntensorflow\n \nas\n \ntf\n\n\nimport\n \nnumpy\n \nas\n \nnp\n\n\nimport\n \nmatplotlib.pyplot\n \nas\n \nplt\n\n\nimport\n \nos\n\n\nimport\n \nmath\n\n\ndef\n \nadd_layer\n(\ninputs\n,\n \nin_size\n,\n \nout_size\n,\n \nactivation_function\n=\nNone\n):\n\n\n    \nWeights\n \n=\n \ntf\n.\nVariable\n(\ntf\n.\nrandom_normal\n([\nin_size\n,\n \nout_size\n]))\n\n    \nbiases\n \n=\n \ntf\n.\nVariable\n(\ntf\n.\nzeros\n([\n1\n,\n \nout_size\n])\n \n+\n \n0.1\n)\n\n    \nWx_plus_b\n \n=\n \ntf\n.\nmatmul\n(\ninputs\n,\n \nWeights\n)\n \n+\n \nbiases\n\n    \nif\n \nactivation_function\n \nis\n \nNone\n:\n\n        \noutputs\n \n=\n \nWx_plus_b\n\n    \nelif\n \nactivation_function\n \n==\n\"Swish\"\n:\n\n        \noutputs\n \n=\n \nWx_plus_b\n/\n(\n1\n+\ntf\n.\nexp\n(\n-\n1\n*\nWx_plus_b\n))\n\n\n    \nelse\n:\n\n        \noutputs\n \n=\n \nactivation_function\n(\nWx_plus_b\n)\n\n    \nreturn\n \noutputs\n,\nWeights\n,\nbiases\n\n\n\ndef\n \nnu\n():\n\n    \n# define placeholder for inputs to network\n\n    \nxs\n \n=\n \ntf\n.\nplaceholder\n(\ntf\n.\nfloat32\n,\n \n[\nNone\n,\n \n1\n])\n\n    \nys\n \n=\n \ntf\n.\nplaceholder\n(\ntf\n.\nfloat32\n,\n \n[\nNone\n,\n \n1\n])\n\n    \n# add hidden layer \u96b1\u85cf\u5c64\n\n    \nneural_node\n=\n150\n\n    \nl1\n \n,\nWeights1\n,\nbiases1\n=\n \nadd_layer\n(\nxs\n,\n \n1\n,\n \nneural_node\n,\n \nactivation_function\n=\ntf\n.\nsigmoid\n)\n\n\n\n\n    \n# add output layer \u8f38\u51fa\u5c64\n\n    \nprediction\n \n,\nWeights2\n,\nbiases2\n=\n \nadd_layer\n(\nl1\n,\n \nneural_node\n,\n \n1\n,\n \nactivation_function\n=\nNone\n)\n\n\n    \n# the error between prediction and real data\n\n    \nloss\n \n=\n \ntf\n.\nreduce_mean\n(\ntf\n.\nreduce_sum\n(\ntf\n.\nsquare\n(\nys\n-\nprediction\n),\n \nreduction_indices\n=\n[\n1\n]))\n\n    \n#loss=tf.square(ys-prediction)\n\n    \ntrain_step\n \n=\n \ntf\n.\ntrain\n.\nRMSPropOptimizer\n(\n0.01\n)\n.\nminimize\n(\nloss\n)\n\n    \n# important step\n\n    \nsess\n \n=\n \ntf\n.\nSession\n()\n\n    \ninit\n \n=\n \ntf\n.\nglobal_variables_initializer\n()\n\n    \nsess\n.\nrun\n(\ninit\n)\n\n    \nreturn\n  \nsess\n,\ntrain_step\n,\nxs\n,\nys\n,\nprediction\n\n\n\n\nx_data\n \n=\n \nnp\n.\nlinspace\n(\n-\n5\n,\n \n10\n,\n \n1000\n)[:,\n \nnp\n.\nnewaxis\n]\n\n\nnoise\n \n=\n \nnp\n.\nrandom\n.\nnormal\n(\n0\n,\n \n0.05\n,\n \nx_data\n.\nshape\n)\n\n\ny_data\n \n=\n \n2\n*\nx_data\n**\n3\n*\n(\nnp\n.\nsin\n(\nx_data\n)\n/\n2\n)\n \n-\n \n0.5\n \n+\n \nnoise\n*\n300\n\n\n\n# plot the real data\n\n\n\n\nfig\n \n=\n \nplt\n.\nfigure\n()\n\n\nax\n \n=\n \nfig\n.\nadd_subplot\n(\n1\n,\n1\n,\n1\n)\n\n\n\nax\n.\nscatter\n(\nx_data\n,\n \ny_data\n)\n\n\nlines\n \n=\n \nax\n.\nplot\n(\n3\n,\n \n3\n,\n \n'r-'\n,\n \nlw\n=\n1\n)\n\n\nax\n.\nlegend\n(\nlabels\n=\n[\n'prediction line'\n,\n'y=2$x^{3(sin(x)/2)}-0.5+noise*300$'\n],\nloc\n=\n'best'\n)\n\n\nplt\n.\nion\n()\n\n\nplt\n.\npause\n(\n2.5\n)\n\n\nplt\n.\nshow\n()\n\n\n\n\n\n\n\n\n\n# start\n\n\nsess\n,\ntrain_step\n,\nxs\n,\nys\n,\nprediction\n=\nnu\n()\n\n\nfor\n \ni\n \nin\n \nrange\n(\n100000\n):\n\n\n    \n# training\n\n\n    \nsess\n.\nrun\n(\ntrain_step\n,\n \nfeed_dict\n=\n{\nxs\n:\n \nx_data\n,\n \nys\n:\n \ny_data\n})\n\n    \nif\n \ni\n \n%\n \n300\n \n==\n \n0\n:\n\n        \n# to visualize the result and improvement\n\n        \ntry\n:\n\n            \nax\n.\nlines\n.\nremove\n(\nlines\n[\n0\n])\n\n        \nexcept\n \nException\n:\n\n            \npass\n\n        \nx_data2\n \n=\n \nnp\n.\nlinspace\n(\n-\n5\n,\n \n10\n,\n \n5000\n)[:,\nnp\n.\nnewaxis\n]\n\n        \nprediction_value\n \n=\n \nsess\n.\nrun\n(\nprediction\n,\n \nfeed_dict\n=\n{\nxs\n:\n \nx_data\n})\n\n\n\n        \n# plot the prediction\n\n        \nlines\n \n=\n \nax\n.\nplot\n(\nx_data\n,\n \nprediction_value\n,\n \n'r-'\n,\n \nlw\n=\n5\n)\n\n        \nplt\n.\npause\n(\n0.000000001\n)",
            "title": "MLP(Regression)"
        },
        {
            "location": "/Machine Learning/Neural Networks/Multilayer perceptron/MLP(Regression)/#mlpregression",
            "text": "",
            "title": "MLP(Regression)"
        },
        {
            "location": "/Machine Learning/Neural Networks/Multilayer perceptron/MLP(Regression)/#type-of-machine-learning",
            "text": "Output Space  Data Label  Protocol  Input Space      Binary Classification  Supervised  Online  Raw     \n\u8a72\u7bc4\u4f8b\u7684\u7d50\u69cb      Info  In this sample is Fully connected three-layered MLP network with 150 neurons in the hidden layer.    Full connected:\u5168\u9023\u63a5\u5c64  MLP (\u591a\u5c64\u611f\u77e5\u5668):\u52a0\u4e0aactivation function\u8ddf\u53cd\u5411\u50b3\u905e\u6f14\u7b97\u6cd5   Code from   __future__   import   print_function  import   tensorflow   as   tf  import   numpy   as   np  import   matplotlib.pyplot   as   plt  import   os  import   math  def   add_layer ( inputs ,   in_size ,   out_size ,   activation_function = None ): \n\n     Weights   =   tf . Variable ( tf . random_normal ([ in_size ,   out_size ])) \n     biases   =   tf . Variable ( tf . zeros ([ 1 ,   out_size ])   +   0.1 ) \n     Wx_plus_b   =   tf . matmul ( inputs ,   Weights )   +   biases \n     if   activation_function   is   None : \n         outputs   =   Wx_plus_b \n     elif   activation_function   == \"Swish\" : \n         outputs   =   Wx_plus_b / ( 1 + tf . exp ( - 1 * Wx_plus_b )) \n\n     else : \n         outputs   =   activation_function ( Wx_plus_b ) \n     return   outputs , Weights , biases  def   nu (): \n     # define placeholder for inputs to network \n     xs   =   tf . placeholder ( tf . float32 ,   [ None ,   1 ]) \n     ys   =   tf . placeholder ( tf . float32 ,   [ None ,   1 ]) \n     # add hidden layer \u96b1\u85cf\u5c64 \n     neural_node = 150 \n     l1   , Weights1 , biases1 =   add_layer ( xs ,   1 ,   neural_node ,   activation_function = tf . sigmoid ) \n\n\n\n     # add output layer \u8f38\u51fa\u5c64 \n     prediction   , Weights2 , biases2 =   add_layer ( l1 ,   neural_node ,   1 ,   activation_function = None ) \n\n     # the error between prediction and real data \n     loss   =   tf . reduce_mean ( tf . reduce_sum ( tf . square ( ys - prediction ),   reduction_indices = [ 1 ])) \n     #loss=tf.square(ys-prediction) \n     train_step   =   tf . train . RMSPropOptimizer ( 0.01 ) . minimize ( loss ) \n     # important step \n     sess   =   tf . Session () \n     init   =   tf . global_variables_initializer () \n     sess . run ( init ) \n     return    sess , train_step , xs , ys , prediction  x_data   =   np . linspace ( - 5 ,   10 ,   1000 )[:,   np . newaxis ]  noise   =   np . random . normal ( 0 ,   0.05 ,   x_data . shape )  y_data   =   2 * x_data ** 3 * ( np . sin ( x_data ) / 2 )   -   0.5   +   noise * 300  # plot the real data  fig   =   plt . figure ()  ax   =   fig . add_subplot ( 1 , 1 , 1 )  ax . scatter ( x_data ,   y_data )  lines   =   ax . plot ( 3 ,   3 ,   'r-' ,   lw = 1 )  ax . legend ( labels = [ 'prediction line' , 'y=2$x^{3(sin(x)/2)}-0.5+noise*300$' ], loc = 'best' )  plt . ion ()  plt . pause ( 2.5 )  plt . show ()  # start  sess , train_step , xs , ys , prediction = nu ()  for   i   in   range ( 100000 ): \n\n     # training \n\n     sess . run ( train_step ,   feed_dict = { xs :   x_data ,   ys :   y_data }) \n     if   i   %   300   ==   0 : \n         # to visualize the result and improvement \n         try : \n             ax . lines . remove ( lines [ 0 ]) \n         except   Exception : \n             pass \n         x_data2   =   np . linspace ( - 5 ,   10 ,   5000 )[:, np . newaxis ] \n         prediction_value   =   sess . run ( prediction ,   feed_dict = { xs :   x_data }) \n\n\n         # plot the prediction \n         lines   =   ax . plot ( x_data ,   prediction_value ,   'r-' ,   lw = 5 ) \n         plt . pause ( 0.000000001 )",
            "title": "Type Of Machine Learning"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/",
            "text": "PLA(Classification)\n\u00b6\n\n\nPerceptron Learning Algorithm\n\n\nType Of this Sample\n\u00b6\n\n\n\n\n\n\n\n\nOutput Space\n\n\nData Label\n\n\nProtocol\n\n\nInput Space\n\n\n\n\n\n\n\n\n\n\nBinary Classification\n\n\nSupervised\n\n\nOnline\n\n\nRaw\n\n\n\n\n\n\n\n\nAlgorithm\n\u00b6\n\n\n\n\n\n\n\n\n\u627e\u5230\u4e00\u689d\u7dda\u80fd\u5206\u958b\u5169\u7a2e\u7d50\u679c\n\n\n\u5982\u4f55\u4fee\u6539\u7dda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u53ef\u4ee5\u5bb9\u932f\u662fpla\u8b8a\u5f62\u6f14\u7b97\u6cd5\u53ebpocket\n\n\nImplement PLA (Classification)\n\u00b6\n\n\nsample version\n\u00b6\n\n\nCode\nimport\n \nmatplotlib.pyplot\n \nas\n \nplt\n\n\nimport\n \nnumpy\n \nas\n \nnp\n\n\n\n#\u7db2\u8def\u4e0a\u627e\u7684dataset \u53ef\u4ee5\u7dda\u6027\u5206\u5272\n\n\n\ndataset\n \n=\n \nnp\n.\narray\n([\n\n\n((\n1\n,\n \n1\n,\n \n5\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n2\n,\n \n4\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n3\n,\n \n3\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n4\n,\n \n2\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n1\n,\n \n6\n),\n \n1\n),\n\n\n((\n1\n,\n \n2\n,\n \n5\n),\n \n1\n),\n\n\n((\n1\n,\n \n3\n,\n \n4\n),\n \n1\n),\n\n\n((\n1\n,\n \n4\n,\n \n3\n),\n \n1\n)])\n\n\n# 1 mean to display -c/b if c=0 i was error\n\n\n# ax+by+c=0\n\n\n#y=(-a/b)x+(-c/b)\n\n\n#\n\n\n#\u5224\u65b7\u6709\u6c92\u6709\u5206\u985e\u932f\u8aa4\uff0c\u4e26\u5217\u5370\u932f\u8aa4\u7387\n\n\n\ndef\n \ncheck_error\n(\nw\n,\n \ndataset\n):\n\n    \nresult\n \n=\n \nNone\n\n    \nerror\n \n=\n \n0\n\n    \nfor\n \nx\n,\n \ns\n \nin\n \ndataset\n:\n\n        \nx\n \n=\n \nnp\n.\narray\n(\nx\n)\n\n        \nprint\n(\nw\n.\nT\n.\ndot\n(\nx\n))\n\n        \nif\n \nint\n(\nnp\n.\nsign\n(\nw\n.\nT\n.\ndot\n(\nx\n)))\n \n!=\n \ns\n:\n\n            \n#\u5e36\u5165ax+by+c=0 \u5982\u679c\u7b26\u865f\u4e0d\u76f8\u7b49\u4ee3\u8868\u6709\u932f\u8aa4\n\n\n            \n# T transpose\n\n            \nresult\n \n=\n  \nx\n,\n \ns\n\n            \nerror\n \n+=\n \n1\n\n    \nprint\n  \n(\n\"error=\n%s\n/\n%s\n\"\n \n%\n \n(\nerror\n,\n \nlen\n(\ndataset\n)))\n\n    \nreturn\n \nresult\n\n\n\n#PLA\u6f14\u7b97\u6cd5\u5be6\u4f5c\n\n\n#Cyclic PLA\n\n\ndef\n \npla\n(\ndataset\n):\n\n\n    \n#ax+by+c=0 \u7dda\u6027\u65b9\u7a0b\u5f0f\u7684\u6cd5\u5411\u91cf\n\n    \nw\n \n=\n \nnp\n.\nzeros\n(\n3\n)\n#\u6cd5\u5411\u91cf\n\n    \nindex\n=\n0\n\n    \nwhile\n \ncheck_error\n(\nw\n,\n \ndataset\n)\n \nis\n \nnot\n \nNone\n:\n\n\n\n        \nx\n,\n \ns\n \n=\n \ncheck_error\n(\nw\n,\n \ndataset\n)\n\n\n        \nw\n \n+=\n \n(\ns\n)\n \n*\n \nx\n \n#Algorithm kernel\n\n\n        \n#fig by algorithm(1).md\n\n        \nindex\n=\nindex\n+\n1\n\n\n    \nreturn\n \nw\n\n\n\n\ndef\n \nprint_image\n(\nw\n):\n\n\n    \n#\u756b\u5716\n\n    \nps\n \n=\n \n[\nv\n[\n0\n]\n \nfor\n \nv\n \nin\n \ndataset\n]\n\n    \nvalue\n \n=\n \n[\nv\n[\n1\n]\n \nfor\n \nv\n \nin\n \ndataset\n]\n\n    \nfig\n \n=\n \nplt\n.\nfigure\n()\n\n    \nax1\n \n=\n \nfig\n.\nadd_subplot\n(\n111\n)\n\n    \n#111 is control code 1\n\n    \n#These are subplot grid parameters encoded as a single integer. For example, \"111\" means \"1x1 grid, first subplot\" and \"234\" means \"2x3 grid, 4th subplot\".\n\n    \n#dataset\u524d\u534a\u5f8c\u534a\u5df2\u7d93\u5206\u5272\u597d \u76f4\u63a5\u756b\u5c31\u662f\n\n    \nindex\n=\n0\n\n\n    \nmax_x\n=\nps\n[\n0\n][\n1\n]\n\n    \nmin_x\n=\nps\n[\n0\n][\n1\n]\n\n    \nfor\n \nv\n \nin\n \nvalue\n:\n\n        \n#print(index)\n\n        \nif\n \nv\n>\n0\n:\n\n            \nax1\n.\nscatter\n(\nps\n[\nindex\n][\n1\n],\nps\n[\nindex\n][\n2\n],\n \nc\n=\n'b'\n,\n \nmarker\n=\n\"o\"\n)\n\n        \nelif\n \nv\n<\n0\n:\n\n            \nax1\n.\nscatter\n(\nps\n[\nindex\n][\n1\n],\nps\n[\nindex\n][\n2\n]\n \n,\n \nc\n=\n'r'\n,\n \nmarker\n=\n\"x\"\n)\n\n        \nelse\n:\n\n            \npass\n\n        \nif\n \nmax_x\n<\nps\n[\nindex\n][\n1\n]:\n\n            \nmax_x\n=\nps\n[\nindex\n][\n1\n]\n\n        \nif\n \nmin_x\n>\nps\n[\nindex\n][\n1\n]:\n\n            \nmin_x\n=\nps\n[\nindex\n][\n1\n]\n\n        \nindex\n=\nindex\n+\n1\n\n\n    \nl\n \n=\n \nnp\n.\nlinspace\n(\nmin_x\n-\n1\n,\nmax_x\n+\n1\n)\n\n    \n#define the line x-axis size\n\n    \na\n,\nb\n \n=\n \n-\nw\n[\n1\n]\n/\nw\n[\n2\n],\n \n-\nw\n[\n0\n]\n/\nw\n[\n2\n]\n\n    \n#a=\u659c\u7387 b\u5e38\u6578\n\n    \nax1\n.\nplot\n(\nl\n,\n \na\n*\nl\n \n+\n \nb\n,\n \n'b-'\n)\n\n\n    \nplt\n.\nshow\n()\n\n\n\n\nw\n \n=\n \npla\n(\ndataset\n)\n\n\nprint_image\n(\nw\n)\n\n\n\n\nOptimizer Version\n\u00b6\n\n\n\u8017\u6642\u2153\n\n\nCode\nimport\n \nmatplotlib.pyplot\n \nas\n \nplt\n\n\nimport\n \nnumpy\n \nas\n \nnp\n\n\nimport\n \nrandom\n\n\n#\u7db2\u8def\u4e0a\u627e\u7684dataset \u53ef\u4ee5\u7dda\u6027\u5206\u5272\n\n\n\ndataset\n \n=\n \nnp\n.\narray\n([\n\n\n((\n1\n,\n \n1.6\n,\n \n5\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n2\n,\n \n4\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n3\n,\n \n3\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n4\n,\n \n2\n),\n \n-\n1\n),\n\n\n((\n1\n,\n \n1\n,\n \n6\n),\n \n1\n),\n\n\n((\n1\n,\n \n2\n,\n \n5\n),\n \n1\n),\n\n\n((\n1\n,\n \n3\n,\n \n4\n),\n \n1\n),\n\n\n((\n1\n,\n \n4\n,\n \n3\n),\n \n1\n)])\n\n\n# 1 mean to display -c/b if c=0 i was error\n\n\n# ax+by+c=0\n\n\n#y=(-a/b)x+(-c/b)\n\n\n#\n\n\n#\u5224\u65b7\u6709\u6c92\u6709\u5206\u985e\u932f\u8aa4\uff0c\u4e26\u5217\u5370\u932f\u8aa4\u7387\n\n\nbad\n=\n0\n\n\ndef\n \ncheck_error\n(\nw\n,\n \ndataset\n):\n\n    \nresult\n \n=\n \nNone\n\n    \nresult\n=\n[]\n\n    \nerror\n \n=\n \n0\n\n    \nfor\n \nx\n,\n \ns\n \nin\n \ndataset\n:\n\n        \nx\n \n=\n \nnp\n.\narray\n(\nx\n)\n\n        \nprint\n(\nw\n.\nT\n.\ndot\n(\nx\n))\n\n        \nif\n \nint\n(\nnp\n.\nsign\n(\nw\n.\nT\n.\ndot\n(\nx\n)))\n \n!=\n \ns\n:\n\n            \n#\u5e36\u5165ax+by+c=0 \u5982\u679c\u7b26\u865f\u4e0d\u76f8\u7b49\u4ee3\u8868\u6709\u932f\u8aa4\n\n\n            \n# T transpose\n\n            \ntem\n=\n[]\n\n            \ntem\n.\nappend\n(\nx\n)\n\n\n            \ntem\n.\nappend\n(\ns\n)\n\n\n            \nresult\n.\nappend\n(\ntem\n)\n\n\n            \nerror\n \n+=\n \n1\n\n    \nprint\n  \n(\n\"error=\n%s\n/\n%s\n\"\n \n%\n \n(\nerror\n,\n \nlen\n(\ndataset\n)))\n\n    \nbad\n=\nerror\n/\nlen\n(\ndataset\n)\n\n\n    \nif\n \nerror\n==\n0\n:\n\n        \nresult\n=\nNone\n\n        \nreturn\n \nresult\n\n\n    \n#\u512a\u5316\u5340\u584a1 \u6bcf\u6b21\u9078\u64c7\u7684\u932f\u8aa4\u7528\u96a8\u6a5f\u6240\u4ee5\u4e0d\u6703\u4e00\u6a23\n\n\n##############################################\n\n\n    \nreturn\n \nresult\n[\nrandom\n.\nrandrange\n(\n0\n,\nerror\n,\n \n1\n)]\n\n\n\n\n#PLA\u6f14\u7b97\u6cd5\u5be6\u4f5c\n\n\n#Cyclic PLA\n\n\ndef\n \npla\n(\ndataset\n):\n\n\n    \n#ax+by+c=0 \u7dda\u6027\u65b9\u7a0b\u5f0f\n\n    \nw\n \n=\n \nnp\n.\nzeros\n(\n3\n)\n\n    \nax\n,\nplt\n=\nprint_image\n(\nw\n)\n\n    \n#print (w)\n\n\n    \nindex\n=\n0\n\n    \nwhile\n \ncheck_error\n(\nw\n,\n \ndataset\n)\n \nis\n \nnot\n \nNone\n:\n\n\n\n        \nx\n,\n \ns\n \n=\n \ncheck_error\n(\nw\n,\n \ndataset\n)\n\n        \n##\u512a\u5316\u5340\u584a2 \u628abaise\u7528\u96a8\u6a5f \u8b93\u5b83\u8b8a\u52d5\u5feb\u9ede\n\n\n        \nx\n[\n0\n]\n=\n(\n1\n-\nbad\n)\n*\nx\n[\n0\n]\n*\nrandom\n.\nuniform\n(\n1\n,\n4\n)\n\n\n        \n#############################################\n\n        \nw\n \n+=\n \n(\ns\n)\n \n*\n \nx\n\n        \ntry\n:\n\n            \nax\n.\nlines\n.\nremove\n(\nlines\n[\n0\n])\n\n        \nexcept\n \nException\n:\n\n            \npass\n\n        \nl\n \n=\n \nnp\n.\nlinspace\n(\n0\n,\n4\n)\n\n        \n#define the line x-axis size\n\n        \na\n,\nb\n \n=\n \n-\nw\n[\n1\n]\n/\nw\n[\n2\n],\n \n-\nw\n[\n0\n]\n/\nw\n[\n2\n]\n\n        \n#a=\u659c\u7387 b\u5e38\u6578\n\n        \nlines\n=\nax\n.\nplot\n(\nl\n,\n \na\n*\nl\n \n+\n \nb\n,\n \n'b-'\n)\n\n        \n#plt.pause(0.1)\n\n\n        \nprint\n \n(\nw\n)\n\n        \nindex\n=\nindex\n+\n1\n\n    \nprint\n \n(\n\"all run circel\"\n)\n\n    \nprint\n \n(\nindex\n)\n\n    \nplt\n.\npause\n(\n111\n)\n\n    \nreturn\n \nw\n\n\n\n\ndef\n \nprint_image\n(\nw\n):\n\n\n    \n#\u756b\u5716\n\n    \nps\n \n=\n \n[\nv\n[\n0\n]\n \nfor\n \nv\n \nin\n \ndataset\n]\n\n    \nvalue\n \n=\n \n[\nv\n[\n1\n]\n \nfor\n \nv\n \nin\n \ndataset\n]\n\n    \nfig\n \n=\n \nplt\n.\nfigure\n()\n\n    \nax1\n \n=\n \nfig\n.\nadd_subplot\n(\n111\n)\n\n    \n#111 is control code 1\n\n    \n#These are subplot grid parameters encoded as a single integer. For example, \"111\" means \"1x1 grid, first subplot\" and \"234\" means \"2x3 grid, 4th subplot\".\n\n    \n#dataset\u524d\u534a\u5f8c\u534a\u5df2\u7d93\u5206\u5272\u597d \u76f4\u63a5\u756b\u5c31\u662f\n\n    \nindex\n=\n0\n\n\n    \nmax_x\n=\nps\n[\n0\n][\n1\n]\n\n    \nmin_x\n=\nps\n[\n0\n][\n1\n]\n\n    \nfor\n \nv\n \nin\n \nvalue\n:\n\n        \n#print(index)\n\n        \nif\n \nv\n>\n0\n:\n\n            \nax1\n.\nscatter\n(\nps\n[\nindex\n][\n1\n],\nps\n[\nindex\n][\n2\n],\n \nc\n=\n'b'\n,\n \nmarker\n=\n\"o\"\n)\n\n        \nelif\n \nv\n<\n0\n:\n\n            \nax1\n.\nscatter\n(\nps\n[\nindex\n][\n1\n],\nps\n[\nindex\n][\n2\n]\n \n,\n \nc\n=\n'r'\n,\n \nmarker\n=\n\"x\"\n)\n\n        \nelse\n:\n\n            \npass\n\n        \nif\n \nmax_x\n<\nps\n[\nindex\n][\n1\n]:\n\n            \nmax_x\n=\nps\n[\nindex\n][\n1\n]\n\n        \nif\n \nmin_x\n>\nps\n[\nindex\n][\n1\n]:\n\n            \nmin_x\n=\nps\n[\nindex\n][\n1\n]\n\n        \nindex\n=\nindex\n+\n1\n\n\n    \nl\n \n=\n \nnp\n.\nlinspace\n(\nmin_x\n-\n1\n,\nmax_x\n+\n1\n)\n\n    \n#define the line x-axis size\n\n    \na\n,\nb\n \n=\n \n-\nw\n[\n1\n]\n/\nw\n[\n2\n],\n \n-\nw\n[\n0\n]\n/\nw\n[\n2\n]\n\n    \n#a=\u659c\u7387 b\u5e38\u6578\n\n    \nax1\n.\nplot\n(\nl\n,\n \na\n*\nl\n \n+\n \nb\n,\n \n'b-'\n)\n\n    \nplt\n.\nion\n()\n\n    \nplt\n.\nshow\n()\n\n    \nreturn\n \nax1\n,\nplt\n\n\n\nw\n \n=\n \npla\n(\ndataset\n)\n\n\nprint_image\n(\nw\n)\n\n\n\n\n\n\n\u8b49\u660e\u7dda\u6027\u53ef\u5206\u6642PLA\u6f14\u7b97\u6cd5\u6703\u505c\n\u00b6\n\n\n\u53c3\u8003\u7db2\u8def\u6559\u5b78\n\n\n\n\npla\u505c\u4e0d\u4e0b\u4f86 \u6709\u5169\u500b\u539f\u56e0\n\n\n\n\n\u9084\u6c92\u8dd1\u5920\n\n\n\u975e\u7dda\u6027\u53ef\u5206\n\n\n\n\n\n\n\n\n\u7b26\u865f\u89e3\u91cb\n\u00b6\n\n\n\n\nW_{f}^{T}=\nW_{f}^{T}=\n\u771f\u5be6\u60f3\u6c42\u7684\u51fd\u6578(\u901a\u5e38\u672a\u77e5)\n\n\nW_{X}=\nW_{X}=\n\u975e\u5e38\"\u63a5\u8fd1\u7b54\u6848\"\u7684\u51fd\u6578\n\n\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|} \\leq 1\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|} \\leq 1\n\u5169\u500b\u6b63\u898f\u5316\u5411\u91cf\u7684\u5167\u7a4d\u6700\u5927\u70ba1\n\n\nW_{t}=\nW_{t}=\n\u67d0\u4e00\u6642\u9593\u9ede\u7684\u7b54\u6848\n\n\nW_{t+1}=\nW_{t+1}=\n\u8a72\u6642\u9593\u9ede\u66f4\u65b0\u5f8c\u7684\u7b54\u6848\n\n\ny_{n}= {1,-1}\ny_{n}= {1,-1}\n\n\ny=sing(ax+b)\ny=sing(ax+b)\n\u6539\u5beb\u6210\ny_{n}=sing(W_{f}^{T}x_{n})\ny_{n}=sing(W_{f}^{T}x_{n})\n\n\nW_{t+1}=\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}}\nW_{t+1}=\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}}\n\u4fee\u6539\u5411\u91cf\u7684\u6f14\u7b97\u6cd5\u6838\u5fc3\n\n\nX=\nX=\n\u7e3d\u5171\u9700\u8981\u4fee\u6539\u7684\u6b21\u6578\n\n\n\n\n\n\nProof 1\n\u00b6\n\n\n\u5df2\u77e5\n\\color{#7B68EE}{y_{n(t)}W_{f}^{T}x_{n(t)}}\\geq \\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}>0\n\\color{#7B68EE}{y_{n(t)}W_{f}^{T}x_{n(t)}}\\geq \\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}>0\n\u56e0\u70ba\u7dda\u4e0d\u80fd\u78b0\u5230\u9ede\n\n\n\n\n\n\\begin{aligned}\n    W_{f}^{T}W_{t+1}&=W_{f}^{T}(\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}}) \\\\\n   &=W_{f}^{T}W_{t}+\\color{#7B68EE}{W_{f}^{T}y_{n(t)}x_{n(t)}} \\\\\n    &\\geq W_{f}^{T}W_{t}+\\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}\\\\\n    &>W_{f}^{T}W_{t}\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n    W_{f}^{T}W_{t+1}&=W_{f}^{T}(\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}}) \\\\\n   &=W_{f}^{T}W_{t}+\\color{#7B68EE}{W_{f}^{T}y_{n(t)}x_{n(t)}} \\\\\n    &\\geq W_{f}^{T}W_{t}+\\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}\\\\\n    &>W_{f}^{T}W_{t}\n\\end{aligned}\n\n\n\n\n\n\n\nNote\n\n\n\u6240\u4ee5\nW_{f}^{T}W_{t+1}>W_{f}^{T}W_{t}\nW_{f}^{T}W_{t+1}>W_{f}^{T}W_{t}\n\n\u610f\u601d\u662f\u7576\"\"\u5411\u91cf\u9577\u5ea6\u4e00\u6a23\"\"\u7684\u6642\u5019,\u5169\u500b\u5411\u91cf\u5167\u7a4d\u8d8a\u4f86\u8d8a\u5927\u4ee3\u8868\u8d8a\u63a5\u8fd1,\u4e5f\u5c31\u8b49\u660e\u4e86\nW_{t+1}\nW_{t+1}\n\u8d8a\u9760\u8fd1\u7b54\u6848\nW_{f}\nW_{f}\n\n\n\n\n\n\nProof 2\n\u00b6\n\n\n\u5df2\u77e5\ny_{n(t)}W_{t}^Tx_{n(t)}\\leq0\ny_{n(t)}W_{t}^Tx_{n(t)}\\leq0\n,\u56e0\u70ba\nW_{t}^T\nW_{t}^T\n\u6709\u932f\u6240\u4ee5\u6b63\u8ca0\u865f\u8ddf\ny_{n(t)}\ny_{n(t)}\n\u4e00\u5b9a\u4e0d\u540c\n\n\n\n\n\n\\begin{aligned}\n\\| W_{t+1} \\|^2&=\\|W_{t}+y_{n(t)}x_{n(t)}\\|^2 \\\\\n&=\\|W_{t}\\|^2+2y_{n(t)}W_{t}^{T}x_{n(t)}+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+0+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\| W_{t+1} \\|^2&=\\|W_{t}+y_{n(t)}x_{n(t)}\\|^2 \\\\\n&=\\|W_{t}\\|^2+2y_{n(t)}W_{t}^{T}x_{n(t)}+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+0+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}\n\n\n\n\n\n\n\nFinally Proof\n\u00b6\n\n\n\n\nQuestion\n\n\n\n\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\geq ?\n\n\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\geq ?\n\n\n\n\n\n\nBy Proof  1:\n\n\n\n\n\n\\begin{aligned}\nW_{f}^{T}W_{X}&\\geq W_{f}^{T}W_{X-1}+\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq W_{f}^{T}W_{0}+X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\nW_{f}^{T}W_{X}&\\geq W_{f}^{T}W_{X-1}+\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq W_{f}^{T}W_{0}+X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\n\\end{aligned}\n\n\n\n\n\nBy Proof  2:\n\n\n\n\n\n\\begin{aligned}\n\\|W_{X}\\|^2&\\leq \\|W_{X-1}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq \\|W_{0}\\|^2+X*\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq X*\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\|W_{X}\\|^2&\\leq \\|W_{X-1}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq \\|W_{0}\\|^2+X*\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq X*\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}\n\n\n\n\n\nWe have\n\n\n\n\nWhen these two vector's angle is close to 0\n\n\n\n\n\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\approx 1\n\n\n\n\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\approx 1\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{aligned}\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}&\\geq \\frac{X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\|\\sqrt[]{X}*\\underset{n}{max}\\|x_{n}\\|}\\\\\n1&\\geq \\sqrt[]{X} *\\frac{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}\n\\end{aligned}\n\n\n\n\n\\begin{aligned}\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}&\\geq \\frac{X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\|\\sqrt[]{X}*\\underset{n}{max}\\|x_{n}\\|}\\\\\n1&\\geq \\sqrt[]{X} *\\frac{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}\n\\end{aligned}\n\n\n\n\n\n\n\n\n\nConclusion\n\u00b6\n\n\n\"So we know PLA Algorithm have upper bound of runing time \nX\nX\n\"\n\n\n\n\n\n{(\\frac{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}})}^2 \\geq X\n\n\n\n\n{(\\frac{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}})}^2 \\geq X\n\n\n\n\n\n\n\n\u8a72\u8b49\u660e\u5be6\u52d9\u4e0a\u7684\u7f3a\u9ede\n\n\n\u516c\u5f0f\u7b97\u4e0d\u51fa\u591a\u4e45\u6703\u505c \u56e0\u70ba\nW_{f}\u662f\u672a\u77e5\u7684\nW_{f}\u662f\u672a\u77e5\u7684\n ,\u6211\u5011\u53ea\u8b49\u660e\u51fa \u7576\u7dda\u6027\u53ef\u5206\u6642 pla\u6703\u505c \u6709\u4e0a\u9650, \u4f46\u4e0a\u9650\u591a\u5c11\u4e0d\u77e5\u9053\n\n\n\n\n\u7df4\u7fd2\u984c\n\u00b6",
            "title": "PLA(Classification)"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#placlassification",
            "text": "Perceptron Learning Algorithm",
            "title": "PLA(Classification)"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#type-of-this-sample",
            "text": "Output Space  Data Label  Protocol  Input Space      Binary Classification  Supervised  Online  Raw",
            "title": "Type Of this Sample"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#algorithm",
            "text": "\u627e\u5230\u4e00\u689d\u7dda\u80fd\u5206\u958b\u5169\u7a2e\u7d50\u679c  \u5982\u4f55\u4fee\u6539\u7dda           \u53ef\u4ee5\u5bb9\u932f\u662fpla\u8b8a\u5f62\u6f14\u7b97\u6cd5\u53ebpocket",
            "title": "Algorithm"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#implement-pla-classification",
            "text": "",
            "title": "Implement PLA (Classification)"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#sample-version",
            "text": "Code import   matplotlib.pyplot   as   plt  import   numpy   as   np  #\u7db2\u8def\u4e0a\u627e\u7684dataset \u53ef\u4ee5\u7dda\u6027\u5206\u5272  dataset   =   np . array ([  (( 1 ,   1 ,   5 ),   - 1 ),  (( 1 ,   2 ,   4 ),   - 1 ),  (( 1 ,   3 ,   3 ),   - 1 ),  (( 1 ,   4 ,   2 ),   - 1 ),  (( 1 ,   1 ,   6 ),   1 ),  (( 1 ,   2 ,   5 ),   1 ),  (( 1 ,   3 ,   4 ),   1 ),  (( 1 ,   4 ,   3 ),   1 )])  # 1 mean to display -c/b if c=0 i was error  # ax+by+c=0  #y=(-a/b)x+(-c/b)  #  #\u5224\u65b7\u6709\u6c92\u6709\u5206\u985e\u932f\u8aa4\uff0c\u4e26\u5217\u5370\u932f\u8aa4\u7387  def   check_error ( w ,   dataset ): \n     result   =   None \n     error   =   0 \n     for   x ,   s   in   dataset : \n         x   =   np . array ( x ) \n         print ( w . T . dot ( x )) \n         if   int ( np . sign ( w . T . dot ( x )))   !=   s : \n             #\u5e36\u5165ax+by+c=0 \u5982\u679c\u7b26\u865f\u4e0d\u76f8\u7b49\u4ee3\u8868\u6709\u932f\u8aa4 \n\n             # T transpose \n             result   =    x ,   s \n             error   +=   1 \n     print    ( \"error= %s / %s \"   %   ( error ,   len ( dataset ))) \n     return   result  #PLA\u6f14\u7b97\u6cd5\u5be6\u4f5c  #Cyclic PLA  def   pla ( dataset ): \n\n     #ax+by+c=0 \u7dda\u6027\u65b9\u7a0b\u5f0f\u7684\u6cd5\u5411\u91cf \n     w   =   np . zeros ( 3 ) #\u6cd5\u5411\u91cf \n     index = 0 \n     while   check_error ( w ,   dataset )   is   not   None : \n\n\n         x ,   s   =   check_error ( w ,   dataset )           w   +=   ( s )   *   x   #Algorithm kernel           #fig by algorithm(1).md \n         index = index + 1 \n\n     return   w  def   print_image ( w ): \n\n     #\u756b\u5716 \n     ps   =   [ v [ 0 ]   for   v   in   dataset ] \n     value   =   [ v [ 1 ]   for   v   in   dataset ] \n     fig   =   plt . figure () \n     ax1   =   fig . add_subplot ( 111 ) \n     #111 is control code 1 \n     #These are subplot grid parameters encoded as a single integer. For example, \"111\" means \"1x1 grid, first subplot\" and \"234\" means \"2x3 grid, 4th subplot\". \n     #dataset\u524d\u534a\u5f8c\u534a\u5df2\u7d93\u5206\u5272\u597d \u76f4\u63a5\u756b\u5c31\u662f \n     index = 0 \n\n     max_x = ps [ 0 ][ 1 ] \n     min_x = ps [ 0 ][ 1 ] \n     for   v   in   value : \n         #print(index) \n         if   v > 0 : \n             ax1 . scatter ( ps [ index ][ 1 ], ps [ index ][ 2 ],   c = 'b' ,   marker = \"o\" ) \n         elif   v < 0 : \n             ax1 . scatter ( ps [ index ][ 1 ], ps [ index ][ 2 ]   ,   c = 'r' ,   marker = \"x\" ) \n         else : \n             pass \n         if   max_x < ps [ index ][ 1 ]: \n             max_x = ps [ index ][ 1 ] \n         if   min_x > ps [ index ][ 1 ]: \n             min_x = ps [ index ][ 1 ] \n         index = index + 1 \n\n     l   =   np . linspace ( min_x - 1 , max_x + 1 ) \n     #define the line x-axis size \n     a , b   =   - w [ 1 ] / w [ 2 ],   - w [ 0 ] / w [ 2 ] \n     #a=\u659c\u7387 b\u5e38\u6578 \n     ax1 . plot ( l ,   a * l   +   b ,   'b-' ) \n\n     plt . show ()  w   =   pla ( dataset )  print_image ( w )",
            "title": "sample version"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#optimizer-version",
            "text": "\u8017\u6642\u2153  Code import   matplotlib.pyplot   as   plt  import   numpy   as   np  import   random  #\u7db2\u8def\u4e0a\u627e\u7684dataset \u53ef\u4ee5\u7dda\u6027\u5206\u5272  dataset   =   np . array ([  (( 1 ,   1.6 ,   5 ),   - 1 ),  (( 1 ,   2 ,   4 ),   - 1 ),  (( 1 ,   3 ,   3 ),   - 1 ),  (( 1 ,   4 ,   2 ),   - 1 ),  (( 1 ,   1 ,   6 ),   1 ),  (( 1 ,   2 ,   5 ),   1 ),  (( 1 ,   3 ,   4 ),   1 ),  (( 1 ,   4 ,   3 ),   1 )])  # 1 mean to display -c/b if c=0 i was error  # ax+by+c=0  #y=(-a/b)x+(-c/b)  #  #\u5224\u65b7\u6709\u6c92\u6709\u5206\u985e\u932f\u8aa4\uff0c\u4e26\u5217\u5370\u932f\u8aa4\u7387  bad = 0  def   check_error ( w ,   dataset ): \n     result   =   None \n     result = [] \n     error   =   0 \n     for   x ,   s   in   dataset : \n         x   =   np . array ( x ) \n         print ( w . T . dot ( x )) \n         if   int ( np . sign ( w . T . dot ( x )))   !=   s : \n             #\u5e36\u5165ax+by+c=0 \u5982\u679c\u7b26\u865f\u4e0d\u76f8\u7b49\u4ee3\u8868\u6709\u932f\u8aa4 \n\n             # T transpose \n             tem = [] \n             tem . append ( x ) \n\n             tem . append ( s ) \n\n             result . append ( tem ) \n\n             error   +=   1 \n     print    ( \"error= %s / %s \"   %   ( error ,   len ( dataset ))) \n     bad = error / len ( dataset ) \n\n     if   error == 0 : \n         result = None \n         return   result \n\n     #\u512a\u5316\u5340\u584a1 \u6bcf\u6b21\u9078\u64c7\u7684\u932f\u8aa4\u7528\u96a8\u6a5f\u6240\u4ee5\u4e0d\u6703\u4e00\u6a23  ##############################################       return   result [ random . randrange ( 0 , error ,   1 )]   #PLA\u6f14\u7b97\u6cd5\u5be6\u4f5c  #Cyclic PLA  def   pla ( dataset ): \n\n     #ax+by+c=0 \u7dda\u6027\u65b9\u7a0b\u5f0f \n     w   =   np . zeros ( 3 ) \n     ax , plt = print_image ( w ) \n     #print (w) \n\n     index = 0 \n     while   check_error ( w ,   dataset )   is   not   None : \n\n\n         x ,   s   =   check_error ( w ,   dataset ) \n         ##\u512a\u5316\u5340\u584a2 \u628abaise\u7528\u96a8\u6a5f \u8b93\u5b83\u8b8a\u52d5\u5feb\u9ede           x [ 0 ] = ( 1 - bad ) * x [ 0 ] * random . uniform ( 1 , 4 )           ############################################# \n         w   +=   ( s )   *   x \n         try : \n             ax . lines . remove ( lines [ 0 ]) \n         except   Exception : \n             pass \n         l   =   np . linspace ( 0 , 4 ) \n         #define the line x-axis size \n         a , b   =   - w [ 1 ] / w [ 2 ],   - w [ 0 ] / w [ 2 ] \n         #a=\u659c\u7387 b\u5e38\u6578 \n         lines = ax . plot ( l ,   a * l   +   b ,   'b-' ) \n         #plt.pause(0.1) \n\n         print   ( w ) \n         index = index + 1 \n     print   ( \"all run circel\" ) \n     print   ( index ) \n     plt . pause ( 111 ) \n     return   w  def   print_image ( w ): \n\n     #\u756b\u5716 \n     ps   =   [ v [ 0 ]   for   v   in   dataset ] \n     value   =   [ v [ 1 ]   for   v   in   dataset ] \n     fig   =   plt . figure () \n     ax1   =   fig . add_subplot ( 111 ) \n     #111 is control code 1 \n     #These are subplot grid parameters encoded as a single integer. For example, \"111\" means \"1x1 grid, first subplot\" and \"234\" means \"2x3 grid, 4th subplot\". \n     #dataset\u524d\u534a\u5f8c\u534a\u5df2\u7d93\u5206\u5272\u597d \u76f4\u63a5\u756b\u5c31\u662f \n     index = 0 \n\n     max_x = ps [ 0 ][ 1 ] \n     min_x = ps [ 0 ][ 1 ] \n     for   v   in   value : \n         #print(index) \n         if   v > 0 : \n             ax1 . scatter ( ps [ index ][ 1 ], ps [ index ][ 2 ],   c = 'b' ,   marker = \"o\" ) \n         elif   v < 0 : \n             ax1 . scatter ( ps [ index ][ 1 ], ps [ index ][ 2 ]   ,   c = 'r' ,   marker = \"x\" ) \n         else : \n             pass \n         if   max_x < ps [ index ][ 1 ]: \n             max_x = ps [ index ][ 1 ] \n         if   min_x > ps [ index ][ 1 ]: \n             min_x = ps [ index ][ 1 ] \n         index = index + 1 \n\n     l   =   np . linspace ( min_x - 1 , max_x + 1 ) \n     #define the line x-axis size \n     a , b   =   - w [ 1 ] / w [ 2 ],   - w [ 0 ] / w [ 2 ] \n     #a=\u659c\u7387 b\u5e38\u6578 \n     ax1 . plot ( l ,   a * l   +   b ,   'b-' ) \n     plt . ion () \n     plt . show () \n     return   ax1 , plt  w   =   pla ( dataset )  print_image ( w )",
            "title": "Optimizer Version"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#pla",
            "text": "\u53c3\u8003\u7db2\u8def\u6559\u5b78   pla\u505c\u4e0d\u4e0b\u4f86 \u6709\u5169\u500b\u539f\u56e0   \u9084\u6c92\u8dd1\u5920  \u975e\u7dda\u6027\u53ef\u5206",
            "title": "\u8b49\u660e\u7dda\u6027\u53ef\u5206\u6642PLA\u6f14\u7b97\u6cd5\u6703\u505c"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#_1",
            "text": "W_{f}^{T}= W_{f}^{T}= \u771f\u5be6\u60f3\u6c42\u7684\u51fd\u6578(\u901a\u5e38\u672a\u77e5)  W_{X}= W_{X}= \u975e\u5e38\"\u63a5\u8fd1\u7b54\u6848\"\u7684\u51fd\u6578  \\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|} \\leq 1 \\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|} \\leq 1 \u5169\u500b\u6b63\u898f\u5316\u5411\u91cf\u7684\u5167\u7a4d\u6700\u5927\u70ba1  W_{t}= W_{t}= \u67d0\u4e00\u6642\u9593\u9ede\u7684\u7b54\u6848  W_{t+1}= W_{t+1}= \u8a72\u6642\u9593\u9ede\u66f4\u65b0\u5f8c\u7684\u7b54\u6848  y_{n}= {1,-1} y_{n}= {1,-1}  y=sing(ax+b) y=sing(ax+b) \u6539\u5beb\u6210 y_{n}=sing(W_{f}^{T}x_{n}) y_{n}=sing(W_{f}^{T}x_{n})  W_{t+1}=\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}} W_{t+1}=\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}} \u4fee\u6539\u5411\u91cf\u7684\u6f14\u7b97\u6cd5\u6838\u5fc3  X= X= \u7e3d\u5171\u9700\u8981\u4fee\u6539\u7684\u6b21\u6578",
            "title": "\u7b26\u865f\u89e3\u91cb"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#proof-1",
            "text": "\u5df2\u77e5 \\color{#7B68EE}{y_{n(t)}W_{f}^{T}x_{n(t)}}\\geq \\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}>0 \\color{#7B68EE}{y_{n(t)}W_{f}^{T}x_{n(t)}}\\geq \\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}>0 \u56e0\u70ba\u7dda\u4e0d\u80fd\u78b0\u5230\u9ede   \n\\begin{aligned}\n    W_{f}^{T}W_{t+1}&=W_{f}^{T}(\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}}) \\\\\n   &=W_{f}^{T}W_{t}+\\color{#7B68EE}{W_{f}^{T}y_{n(t)}x_{n(t)}} \\\\\n    &\\geq W_{f}^{T}W_{t}+\\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}\\\\\n    &>W_{f}^{T}W_{t}\n\\end{aligned}  \n\\begin{aligned}\n    W_{f}^{T}W_{t+1}&=W_{f}^{T}(\\color{#0000FF}{W_{t}+y_{n(t)}x_{n(t)}}) \\\\\n   &=W_{f}^{T}W_{t}+\\color{#7B68EE}{W_{f}^{T}y_{n(t)}x_{n(t)}} \\\\\n    &\\geq W_{f}^{T}W_{t}+\\color{#007799}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}\\\\\n    &>W_{f}^{T}W_{t}\n\\end{aligned}    Note  \u6240\u4ee5 W_{f}^{T}W_{t+1}>W_{f}^{T}W_{t} W_{f}^{T}W_{t+1}>W_{f}^{T}W_{t} \n\u610f\u601d\u662f\u7576\"\"\u5411\u91cf\u9577\u5ea6\u4e00\u6a23\"\"\u7684\u6642\u5019,\u5169\u500b\u5411\u91cf\u5167\u7a4d\u8d8a\u4f86\u8d8a\u5927\u4ee3\u8868\u8d8a\u63a5\u8fd1,\u4e5f\u5c31\u8b49\u660e\u4e86 W_{t+1} W_{t+1} \u8d8a\u9760\u8fd1\u7b54\u6848 W_{f} W_{f}",
            "title": "Proof 1"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#proof-2",
            "text": "\u5df2\u77e5 y_{n(t)}W_{t}^Tx_{n(t)}\\leq0 y_{n(t)}W_{t}^Tx_{n(t)}\\leq0 ,\u56e0\u70ba W_{t}^T W_{t}^T \u6709\u932f\u6240\u4ee5\u6b63\u8ca0\u865f\u8ddf y_{n(t)} y_{n(t)} \u4e00\u5b9a\u4e0d\u540c   \n\\begin{aligned}\n\\| W_{t+1} \\|^2&=\\|W_{t}+y_{n(t)}x_{n(t)}\\|^2 \\\\\n&=\\|W_{t}\\|^2+2y_{n(t)}W_{t}^{T}x_{n(t)}+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+0+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}  \n\\begin{aligned}\n\\| W_{t+1} \\|^2&=\\|W_{t}+y_{n(t)}x_{n(t)}\\|^2 \\\\\n&=\\|W_{t}\\|^2+2y_{n(t)}W_{t}^{T}x_{n(t)}+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+0+\\|y_{n(t)}x_{n(t)}\\|^2\\\\\n&\\leq \\|W_{t}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}",
            "title": "Proof 2"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#finally-proof",
            "text": "Question   \\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\geq ?  \\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\geq ?    By Proof  1:   \n\\begin{aligned}\nW_{f}^{T}W_{X}&\\geq W_{f}^{T}W_{X-1}+\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq W_{f}^{T}W_{0}+X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\n\\end{aligned}  \n\\begin{aligned}\nW_{f}^{T}W_{X}&\\geq W_{f}^{T}W_{X-1}+\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq W_{f}^{T}W_{0}+X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\\\\\n&\\geq X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}\n\\end{aligned}   By Proof  2:   \n\\begin{aligned}\n\\|W_{X}\\|^2&\\leq \\|W_{X-1}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq \\|W_{0}\\|^2+X*\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq X*\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}  \n\\begin{aligned}\n\\|W_{X}\\|^2&\\leq \\|W_{X-1}\\|^2+\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq \\|W_{0}\\|^2+X*\\underset{n}{max}\\|x_{n}\\|^2\\\\\n&\\leq X*\\underset{n}{max}\\|x_{n}\\|^2\n\\end{aligned}   We have   When these two vector's angle is close to 0   \n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\approx 1  \n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}\\approx 1     Answer   \n\\begin{aligned}\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}&\\geq \\frac{X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\|\\sqrt[]{X}*\\underset{n}{max}\\|x_{n}\\|}\\\\\n1&\\geq \\sqrt[]{X} *\\frac{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}\n\\end{aligned}  \n\\begin{aligned}\n\\frac{W_{f}^{T}}{\\|W_{f}\\|}\\frac{W_{X}}{\\|W_{X}\\|}&\\geq \\frac{X*\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\|\\sqrt[]{X}*\\underset{n}{max}\\|x_{n}\\|}\\\\\n1&\\geq \\sqrt[]{X} *\\frac{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}}{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}\n\\end{aligned}",
            "title": "Finally Proof"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#conclusion",
            "text": "\"So we know PLA Algorithm have upper bound of runing time  X X \"   \n{(\\frac{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}})}^2 \\geq X  \n{(\\frac{\\|W_{f}\\| * \\underset{n}{max}\\|x_{n}\\|}{\\underset{n}{min}~y_{n}W_{f}^{T}x_{n}})}^2 \\geq X    \u8a72\u8b49\u660e\u5be6\u52d9\u4e0a\u7684\u7f3a\u9ede  \u516c\u5f0f\u7b97\u4e0d\u51fa\u591a\u4e45\u6703\u505c \u56e0\u70ba W_{f}\u662f\u672a\u77e5\u7684 W_{f}\u662f\u672a\u77e5\u7684  ,\u6211\u5011\u53ea\u8b49\u660e\u51fa \u7576\u7dda\u6027\u53ef\u5206\u6642 pla\u6703\u505c \u6709\u4e0a\u9650, \u4f46\u4e0a\u9650\u591a\u5c11\u4e0d\u77e5\u9053",
            "title": "Conclusion"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Classification)/#_2",
            "text": "",
            "title": "\u7df4\u7fd2\u984c"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Regression)/",
            "text": "PLA(Regression)\n\u00b6\n\n\nType Of this Sample\n\u00b6\n\n\n\n\n\n\n\n\nOutput Space\n\n\nData Label\n\n\nProtocol\n\n\nInput Space\n\n\n\n\n\n\n\n\n\n\nRegression\n\n\nSupervised\n\n\nOnline\n\n\nRaw\n\n\n\n\n\n\n\n\n\n\u8a72\u7bc4\u4f8b\u6c92\u6709\u4f7f\u7528Activation Function \u6240\u4ee5\u53ea\u80fd\u5b78\u7fd2\u7dda\u6027\n\n\nBackpropagation\n\u00b6\n\n\n\n\nImplement PLA(Regression)\n\u00b6\n\n\n\u8cc7\u6599=10x+5\n\u5617\u8a66\u8981\u8b93\u985e\u795e\u7d93\u85c9\u7531\u6578\u64dax\u8ddfy\u5b78\u5230\u56de\u6b78\u76f4\u7dda\n\u5b78\u7fd2\u6548\u7387\uff1a0.0000001(\u8b93\u901f\u5ea6\u6162\u4e00\u9ede\u597d\u986f\u793a)\n\n\nCode\nimport\n  \ntensorflow\n \nas\n \ntf\n\n\nimport\n \nnumpy\n \nas\n \nnp\n\n\nimport\n \nmatplotlib.pyplot\n \nas\n \nplt\n\n\n\nx_data\n=\nnp\n.\nlinspace\n(\n1\n,\n11\n,\n111\n)\n.\nastype\n(\nnp\n.\nfloat32\n)\n\n\n#x_data=np.random.rand(100).astype(np.float32)\n\n\ny_data\n=\n10\n*\nx_data\n+\n5\n\n\n\n\nWeights\n=\ntf\n.\nVariable\n(\ntf\n.\nzeros\n([\n1\n]))\n\n\n\nbiases\n=\ntf\n.\nVariable\n(\ntf\n.\nzeros\n([\n1\n]))\n\n\n\n\ny\n=\nWeights\n*\nx_data\n+\nbiases\n\n\n\n#loss = tf.reduce_mean(tf.square(y-y_data))#\u7528\u6700\u5c0f\u5e73\u65b9\u6cd5 \u53ef\u4ee5\u6c42\u51fa\u56de\u6b78\u76f4\u7dda \u4e0d\u80fd\u4e82\u7528\n\n\n\nloss\n=\ntf\n.\nreduce_mean\n(\ntf\n.\nreduce_sum\n(\ntf\n.\nsquare\n(\ny\n-\ny_data\n)))\n\n\n#************Optimizer*********\n\n\n#****MomentumOptimizer\n\n\n#optimizer=tf.train.MomentumOptimizer(0.1,0.2)#\u68af\u5ea6\u4e0b\u964d\u6cd5 Gradient descent\n\n\n\n\noptimizer\n=\ntf\n.\ntrain\n.\nGradientDescentOptimizer\n(\n0.0000001\n)\n\n\n\n\ntrain\n \n=\noptimizer\n.\nminimize\n(\nloss\n)\n\n\n\ninit\n=\ntf\n.\nglobal_variables_initializer\n()\n\n\n\nsess\n=\ntf\n.\nSession\n()\n\n\nsess\n.\nrun\n(\ninit\n)\n\n\n\n#*********** for plt\n\n\nfig\n \n=\n \nplt\n.\nfigure\n()\n\n\nax\n \n=\n \nfig\n.\nadd_subplot\n(\n1\n,\n1\n,\n1\n)\n\n\nax\n.\nscatter\n(\nx_data\n,\n \ny_data\n,\ncolor\n=\n\"green\"\n)\n\n\nlines\n \n=\n \nax\n.\nplot\n(\n3\n,\n \n3\n,\n \n'r-'\n,\n \nlw\n=\n1\n)\n\n\nax\n.\nlegend\n(\nlabels\n=\n[\n'prediction line'\n,\n'y=10x+5'\n],\nloc\n=\n'best'\n)\n\n\nplt\n.\nion\n()\n\n\nplt\n.\nshow\n()\n\n\nplt\n.\npause\n(\n2.5\n)\n\n\nfor\n \nstep\n \nin\n \nrange\n(\n20000\n):\n\n    \nif\n \nstep\n \n%\n \n100\n \n==\n \n0\n:\n\n        \n# \u53ea\u662f\u986f\u793a\u53c3\u6578\n\n        \ntry\n:\n\n            \nax\n.\nlines\n.\nremove\n(\nlines\n[\n0\n])\n\n        \nexcept\n \nException\n:\n\n            \npass\n\n        \nprint\n(\nstep\n,\n \nsess\n.\nrun\n(\nWeights\n),\n \nsess\n.\nrun\n(\nbiases\n),\n \nsess\n.\nrun\n(\nloss\n))\n\n        \n#for plt\n\n\n        \nlines\n \n=\n \nax\n.\nplot\n(\nx_data\n,\n \nsess\n.\nrun\n(\ny\n),\n \n'r-'\n,\n \nlw\n=\n1\n)\n\n        \nplt\n.\npause\n(\n1\n)\n\n\n\n    \nsess\n.\nrun\n(\ntrain\n)\n  \n# \u771f\u6b63\u8a13\u7df4\n\n\n\n\n\u5ef6\u4f38\u591a\u5c64\u985e\u795e\u7d93",
            "title": "PLA(Regression)"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Regression)/#plaregression",
            "text": "",
            "title": "PLA(Regression)"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Regression)/#type-of-this-sample",
            "text": "Output Space  Data Label  Protocol  Input Space      Regression  Supervised  Online  Raw     \n\u8a72\u7bc4\u4f8b\u6c92\u6709\u4f7f\u7528Activation Function \u6240\u4ee5\u53ea\u80fd\u5b78\u7fd2\u7dda\u6027",
            "title": "Type Of this Sample"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Regression)/#backpropagation",
            "text": "",
            "title": "Backpropagation"
        },
        {
            "location": "/Machine Learning/Neural Networks/Perceptron Learning Algorithm/PLA(Regression)/#implement-plaregression",
            "text": "\u8cc7\u6599=10x+5\n\u5617\u8a66\u8981\u8b93\u985e\u795e\u7d93\u85c9\u7531\u6578\u64dax\u8ddfy\u5b78\u5230\u56de\u6b78\u76f4\u7dda\n\u5b78\u7fd2\u6548\u7387\uff1a0.0000001(\u8b93\u901f\u5ea6\u6162\u4e00\u9ede\u597d\u986f\u793a)  Code import    tensorflow   as   tf  import   numpy   as   np  import   matplotlib.pyplot   as   plt  x_data = np . linspace ( 1 , 11 , 111 ) . astype ( np . float32 )  #x_data=np.random.rand(100).astype(np.float32)  y_data = 10 * x_data + 5  Weights = tf . Variable ( tf . zeros ([ 1 ]))  biases = tf . Variable ( tf . zeros ([ 1 ]))  y = Weights * x_data + biases  #loss = tf.reduce_mean(tf.square(y-y_data))#\u7528\u6700\u5c0f\u5e73\u65b9\u6cd5 \u53ef\u4ee5\u6c42\u51fa\u56de\u6b78\u76f4\u7dda \u4e0d\u80fd\u4e82\u7528  loss = tf . reduce_mean ( tf . reduce_sum ( tf . square ( y - y_data )))  #************Optimizer*********  #****MomentumOptimizer  #optimizer=tf.train.MomentumOptimizer(0.1,0.2)#\u68af\u5ea6\u4e0b\u964d\u6cd5 Gradient descent  optimizer = tf . train . GradientDescentOptimizer ( 0.0000001 )  train   = optimizer . minimize ( loss )  init = tf . global_variables_initializer ()  sess = tf . Session ()  sess . run ( init )  #*********** for plt  fig   =   plt . figure ()  ax   =   fig . add_subplot ( 1 , 1 , 1 )  ax . scatter ( x_data ,   y_data , color = \"green\" )  lines   =   ax . plot ( 3 ,   3 ,   'r-' ,   lw = 1 )  ax . legend ( labels = [ 'prediction line' , 'y=10x+5' ], loc = 'best' )  plt . ion ()  plt . show ()  plt . pause ( 2.5 )  for   step   in   range ( 20000 ): \n     if   step   %   100   ==   0 : \n         # \u53ea\u662f\u986f\u793a\u53c3\u6578 \n         try : \n             ax . lines . remove ( lines [ 0 ]) \n         except   Exception : \n             pass \n         print ( step ,   sess . run ( Weights ),   sess . run ( biases ),   sess . run ( loss )) \n         #for plt \n\n         lines   =   ax . plot ( x_data ,   sess . run ( y ),   'r-' ,   lw = 1 ) \n         plt . pause ( 1 ) \n\n\n     sess . run ( train )    # \u771f\u6b63\u8a13\u7df4   \u5ef6\u4f38\u591a\u5c64\u985e\u795e\u7d93",
            "title": "Implement PLA(Regression)"
        }
    ]
}